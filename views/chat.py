import threading
from datetime import datetime

import streamlit as st

from config import Config, init_services, CostManager
from ai_engine import (
    AIService,
    ContextManager,
    SmartAIRouter,
    RuleMiningSystem,
    HybridSearch,
    check_semantic_intent,
    get_v7_reminder_message,
)
from ai_verifier import run_verification_loop
from core.executor_v7 import execute_plan
from core.command_parser import is_command_message, parse_command, get_fallback_clarification
from persona import PersonaSystem
from utils.auth_manager import check_permission, submit_pending_change
from utils.python_executor import PythonExecutor


def _get_crystallize_count(project_id, user_id):
    """L·∫•y s·ªë tin nh·∫Øn t·ª´ l·∫ßn crystallize g·∫ßn nh·∫•t (schema v7.1). Tr·∫£ v·ªÅ 0 n·∫øu ch∆∞a c√≥ b·∫£ng."""
    try:
        services = init_services()
        if not services:
            return 0
        r = services["supabase"].table("chat_crystallize_state").select("messages_since_crystallize").eq(
            "story_id", project_id
        ).eq("user_id", str(user_id) or "").limit(1).execute()
        if r.data and len(r.data) > 0:
            return int(r.data[0].get("messages_since_crystallize", 0) or 0)
    except Exception:
        pass
    return 0


def _increment_crystallize_count(project_id, user_id):
    """TƒÉng messages_since_crystallize l√™n 1 (sau khi l∆∞u tin nh·∫Øn V Work)."""
    try:
        services = init_services()
        if not services:
            return
        sb = services["supabase"]
        now = datetime.utcnow().isoformat()
        r = sb.table("chat_crystallize_state").select("messages_since_crystallize").eq(
            "story_id", project_id
        ).eq("user_id", str(user_id) or "").limit(1).execute()
        if r.data and len(r.data) > 0:
            cur = int(r.data[0].get("messages_since_crystallize", 0) or 0)
            sb.table("chat_crystallize_state").update({
                "messages_since_crystallize": cur + 1,
                "updated_at": now,
            }).eq("story_id", project_id).eq("user_id", str(user_id) or "").execute()
        else:
            sb.table("chat_crystallize_state").upsert({
                "story_id": project_id,
                "user_id": str(user_id) or "",
                "messages_since_crystallize": 1,
                "updated_at": now,
            }, on_conflict="story_id,user_id").execute()
    except Exception:
        pass


def _reset_crystallize_count(project_id, user_id):
    """Reset v·ªÅ 0 sau khi crystallize (tr√°nh tr√πng)."""
    try:
        services = init_services()
        if not services:
            return
        now = datetime.utcnow().isoformat()
        services["supabase"].table("chat_crystallize_state").upsert({
            "story_id": project_id,
            "user_id": str(user_id) or "",
            "messages_since_crystallize": 0,
            "updated_at": now,
        }, on_conflict="story_id,user_id").execute()
    except Exception:
        pass


def _after_save_history_v_work(project_id, user_id, persona_role):
    """Sau khi l∆∞u tin nh·∫Øn V Work: tƒÉng counter, n·∫øu >= 30 th√¨ ch·∫°y crystallize (s·∫Ω reset v·ªÅ 0)."""
    if not project_id or not user_id:
        return
    _increment_crystallize_count(project_id, user_id)
    if _get_crystallize_count(project_id, user_id) >= 30:
        threading.Thread(
            target=_auto_crystallize_background,
            args=(project_id, user_id, persona_role),
            daemon=True,
        ).start()


# --- V Home: l∆∞u/load theo topic (kh√¥ng d√πng chat_history) ---
V_HOME_CONTEXT_MESSAGES = 10


def _v_home_get_current_topic_start(user_id):
    """L·∫•y topic_start_at hi·ªán t·∫°i c·ªßa user. N·∫øu ch∆∞a c√≥ th√¨ t·∫°o m·ªõi (now). Tr·∫£ v·ªÅ chu·ªói ISO."""
    if not user_id:
        return datetime.utcnow().isoformat()
    try:
        services = init_services()
        if not services:
            return datetime.utcnow().isoformat()
        r = services["supabase"].table("v_home_current_topic").select("topic_start_at").eq(
            "user_id", str(user_id)
        ).limit(1).execute()
        if r.data and len(r.data) > 0:
            raw = r.data[0].get("topic_start_at")
            if raw is not None:
                return raw if isinstance(raw, str) else getattr(raw, "isoformat", lambda: str(raw))()
        now = datetime.utcnow().isoformat()
        services["supabase"].table("v_home_current_topic").upsert(
            {"user_id": str(user_id), "topic_start_at": now},
            on_conflict="user_id",
        ).execute()
        return now
    except Exception:
        return datetime.utcnow().isoformat()


def _v_home_load_messages(user_id):
    """L·∫•y tin nh·∫Øn thu·ªôc topic hi·ªán t·∫°i (ƒë·ªÉ hi·ªÉn th·ªã v√† l√†m context)."""
    if not user_id:
        return []
    try:
        services = init_services()
        if not services:
            return []
        topic_start = _v_home_get_current_topic_start(user_id)
        r = (
            services["supabase"]
            .table("v_home_messages")
            .select("id, role, content, created_at, topic_start_at")
            .eq("user_id", str(user_id))
            .order("created_at", desc=True)
            .limit(200)
            .execute()
        )
        out = []
        for m in (r.data or []):
            ts = m.get("topic_start_at")
            ts_str = ts if isinstance(ts, str) else (getattr(ts, "isoformat", lambda: str(ts))() if ts else "")
            if ts_str == topic_start:
                out.append(m)
        out.reverse()
        return out
    except Exception:
        return []


def _v_home_reset_topic(user_id):
    """Reset topic: ƒë·∫∑t topic_start_at = now. Tin nh·∫Øn sau ch·ªâ thu·ªôc topic m·ªõi."""
    if not user_id:
        return
    try:
        services = init_services()
        if not services:
            return
        now = datetime.utcnow().isoformat()
        services["supabase"].table("v_home_current_topic").upsert(
            {"user_id": str(user_id), "topic_start_at": now},
            on_conflict="user_id",
        ).execute()
    except Exception:
        pass


def _v_home_save_message(user_id, role, content, topic_start_at):
    """L∆∞u 1 tin nh·∫Øn V Home (kh√¥ng ghi chat_history)."""
    if not user_id:
        return
    try:
        services = init_services()
        if not services:
            return
        services["supabase"].table("v_home_messages").insert({
            "user_id": str(user_id),
            "role": role,
            "content": content,
            "created_at": datetime.utcnow().isoformat(),
            "topic_start_at": topic_start_at,
        }).execute()
    except Exception:
        pass


def _auto_crystallize_background(project_id, user_id, persona_role):
    """Ch·∫°y ng·∫ßm: crystallize 25 tin (30 - 5) v√† l∆∞u v√†o Bible [CHAT] (ng√†y-stt). Reset counter v7.1 v·ªÅ 0."""
    try:
        services = init_services()
        if not services:
            return
        supabase = services["supabase"]
        q = supabase.table("chat_history").select("id, role, content, created_at").eq("story_id", project_id)
        if user_id:
            q = q.eq("user_id", str(user_id))
        r = q.order("created_at", desc=True).limit(35).execute()
        data = list(r.data)[::-1] if r.data else []
        if len(data) < 25:
            return
        to_crystallize = data[:-5]
        chat_text = "\n".join([f"{m['role']}: {m['content']}" for m in to_crystallize])
        summary = RuleMiningSystem.crystallize_session(to_crystallize, persona_role)
        if not summary or summary == "NO_INFO":
            return
        vec = AIService.get_embedding(summary)
        if not vec:
            return
        today = datetime.utcnow().strftime("%Y-%m-%d")
        try:
            log_r = supabase.table("chat_crystallize_log").select("serial_in_day").eq(
                "story_id", project_id
            ).eq("user_id", str(user_id) or "").eq("crystallize_date", today).execute()
            serial = len(log_r.data) + 1 if log_r.data else 1
        except Exception:
            serial = 1
        entity_name = f"[CHAT] {today} chat-{serial}"
        payload = {
            "story_id": project_id,
            "entity_name": entity_name,
            "description": summary,
            "embedding": vec,
            "source_chapter": 0,
        }
        ins = supabase.table("story_bible").insert(payload).execute()
        bible_id = ins.data[0].get("id") if ins.data else None
        try:
            supabase.table("chat_crystallize_log").insert({
                "story_id": project_id,
                "user_id": str(user_id) if user_id else None,
                "crystallize_date": today,
                "serial_in_day": serial,
                "message_count": len(to_crystallize),
                "bible_entry_id": bible_id,
            }).execute()
        except Exception:
            pass
        _reset_crystallize_count(project_id, user_id)
        try:
            from ai_engine import suggest_relations
            suggestions = suggest_relations(summary, project_id)
            for s in (suggestions or []):
                if s.get("kind") == "relation":
                    try:
                        supabase.table("entity_relations").insert({
                            "source_entity_id": s["source_entity_id"],
                            "target_entity_id": s["target_entity_id"],
                            "relation_type": s.get("relation_type", "li√™n quan"),
                            "description": s.get("description", ""),
                            "story_id": project_id,
                        }).execute()
                    except Exception:
                        pass
        except Exception:
            pass
    except Exception as e:
        print(f"auto_crystallize_background error: {e}")


def render_chat_tab(project_id, persona, chat_mode=None):
    """Tab Chat. chat_mode: 'v_work' (d·ª± √°n, persona, router, crystallize) ho·∫∑c 'v_home' (chat t·ª± do, kh√¥ng context d·ª± √°n)."""
    if chat_mode is None:
        chat_mode = "v_work"
    is_v_home = chat_mode == "v_home"

    st.header("üè† V Home" if is_v_home else "üîß V Work")

    col_chat, col_memory = st.columns([3, 1])

    user = st.session_state.get("user")
    user_id = getattr(user, "id", None) if user else None
    user_email = getattr(user, "email", None) if user else None
    can_write = bool(
        project_id
        and user_id
        and check_permission(str(user_id), user_email or "", project_id, "write")
    )
    can_request = bool(
        project_id
        and user_id
        and check_permission(str(user_id), user_email or "", project_id, "request_write")
    )

    with col_memory:
        st.write("### üß† Memory & Settings")
        if is_v_home:
            active_persona = {"icon": "üè†", "role": "Assistant", "core_instruction": "B·∫°n l√† tr·ª£ l√Ω th√¢n thi·ªán. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, h·ªØu √≠ch. Ng√¥n ng·ªØ: ∆∞u ti√™n Ti·∫øng Vi·ªát.", "system_prompt": "", "max_tokens": 4000}
            st.session_state['enable_history'] = False
            st.caption("Chat t·ª± do ‚Äî kh√¥ng l∆∞u v√†o DB d·ª± √°n. Context = 10 tin cu·ªëi c·ªßa topic.")
            if st.button("üîÑ Reset topic", use_container_width=True, key=f"chat_btn_reset_topic_{chat_mode}", help="B·∫Øt ƒë·∫ßu topic m·ªõi: t·ª´ gi·ªù ch·ªâ ƒë∆∞a tin nh·∫Øn sau th·ªùi ƒëi·ªÉm n√†y v√†o context."):
                _v_home_reset_topic(user_id)
                st.toast("ƒê√£ b·∫Øt ƒë·∫ßu topic m·ªõi.")
                st.rerun()
        else:
            available = PersonaSystem.get_available_personas()
            default_key = st.session_state.get("persona", "Writer")
            idx = available.index(default_key) if default_key in available else 0
            selected_persona_key = st.selectbox(
                "Persona tr·∫£ l·ªùi",
                available,
                index=idx,
                key=f"chat_persona_key_{chat_mode}",
                help="Ch·ªçn persona ƒë·ªÉ AI tr·∫£ l·ªùi theo phong c√°ch n√†y."
            )
            active_persona = PersonaSystem.get_persona(selected_persona_key)
            st.session_state['enable_history'] = True

            if st.button("üßπ Clear Screen", use_container_width=True, key=f"chat_btn_clear_{chat_mode}"):
                st.session_state['chat_cutoff'] = datetime.utcnow().isoformat()
                st.rerun()

            if st.button("üîÑ Show All", use_container_width=True, key=f"chat_btn_show_all_{chat_mode}"):
                st.session_state['chat_cutoff'] = "1970-01-01"
                st.rerun()

        if not is_v_home:
            st.session_state['strict_mode'] = st.toggle(
                "üö´ Strict Mode",
                value=st.session_state.get('strict_mode', False),
                help="ON: AI only answers based on found data. No fabrication. (Temp = 0)",
                key=f"chat_toggle_strict_{chat_mode}",
            )
            st.session_state['use_v7_planner'] = st.toggle(
                "üìê V7 Planner",
                value=st.session_state.get('use_v7_planner', False),
                help="V s·∫Ω t∆∞ duy ƒë·ªÉ t√¨m c√¢u tr·∫£ l·ªùi t·ªët nh·∫•t.",
                key=f"chat_toggle_v7_{chat_mode}",
            )
            st.divider()
            st.write("### üï∞Ô∏è Context cho Router / Planner")
            st.session_state["history_depth"] = st.slider(
                "S·ªë tin nh·∫Øn c≈© ƒë∆∞a v√†o Router & V7 Planner",
                min_value=0,
                max_value=50,
                value=st.session_state.get("history_depth", 5),
                step=1,
                help="Bao nhi√™u tin g·∫ßn nh·∫•t ƒë∆∞·ª£c ƒë∆∞a v√†o Router v√† V7 Planner ƒë·ªÉ ch·ªçn intent v√† l√™n k·∫ø ho·∫°ch. Tr·∫£ l·ªùi cu·ªëi d·ª±a tr√™n context t·ª´ Bible/ch∆∞∆°ng ƒë√£ thu th·∫≠p, kh√¥ng nh·ªìi th√™m l·ªãch s·ª≠ chat.",
                key=f"chat_history_depth_{chat_mode}",
            )
            crystallize_count = _get_crystallize_count(project_id, user_id) if project_id and user_id else 0
            st.caption(f"üíé Crystallize: **{crystallize_count} / 30** tin (sau 30 ‚Üí t√≥m t·∫Øt & l∆∞u Bible [CHAT], xem t·∫°i **Knowledge > Bible** ho·∫∑c **Memory**).")
        else:
            st.session_state["history_depth"] = st.session_state.get("history_depth", 5)

    @st.fragment
    def _chat_messages_fragment():
        if is_v_home:
            visible_msgs = _v_home_load_messages(user_id)
            for m in visible_msgs:
                role_icon = active_persona["icon"] if m["role"] == "model" else None
                with st.chat_message(m["role"], avatar=role_icon):
                    st.markdown(m.get("content", ""))
        else:
            try:
                services = init_services()
                supabase = services["supabase"]
                q = (
                    supabase.table("chat_history")
                    .select("*")
                    .eq("story_id", project_id)
                )
                if user_id:
                    q = q.eq("user_id", str(user_id))
                msgs_data = (
                    q.order("created_at", desc=True)
                    .limit(50)
                    .execute()
                )
                msgs = msgs_data.data[::-1] if msgs_data.data else []
                visible_msgs = [m for m in msgs if m["created_at"] > st.session_state.get("chat_cutoff", "1970-01-01")]
                for m in visible_msgs:
                    role_icon = active_persona["icon"] if m["role"] == "model" else None
                    with st.chat_message(m["role"], avatar=role_icon):
                        st.markdown(m["content"])
                        if m.get("metadata"):
                            with st.expander("üìä Details"):
                                st.json(m["metadata"], expanded=False)
            except Exception as e:
                st.error(f"Error loading history: {e}")
        history_depth = st.session_state.get("history_depth", 5)
        chat_input_key = "chat_input_v_home" if is_v_home else "chat_input_main"
        if prompt := st.chat_input(f"Ask {active_persona['icon']} AI Assistant...", key=chat_input_key):
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.spinner("Thinking..."):
                now_timestamp = datetime.utcnow().isoformat()
                v7_handled = False
                router_out = None
                free_chat_mode = is_v_home or st.session_state.get('free_chat_mode', False)

                # S·ªë tin ƒë∆∞a v√†o Router/Planner theo slider (0 = kh√¥ng d√πng l·ªãch s·ª≠).
                depth = history_depth if not is_v_home else 0
                if depth > 0 and visible_msgs:
                    recent_history_text = "\n".join([
                        f"{m['role']}: {m['content']}"
                        for m in visible_msgs[-depth:]
                    ])
                else:
                    recent_history_text = "" if not is_v_home else "\n".join([
                        f"{m.get('role', 'user')}: {m.get('content', '')}"
                        for m in visible_msgs[-V_HOME_CONTEXT_MESSAGES:]
                    ])

                if free_chat_mode:
                    router_out = {"intent": "chat_casual", "target_files": [], "target_bible_entities": [], "rewritten_query": prompt, "chapter_range": None, "chapter_range_mode": None, "chapter_range_count": 5}
                    debug_notes = ["Intent: chat_casual", "üåê Chat t·ª± do"]
                else:
                    debug_notes = []
                    # Ch·ªâ l·ªánh @: parse tr∆∞·ªõc; fallback ask_user_clarification n·∫øu thi·∫øu/sai (kh√¥ng ƒëo√°n √Ω)
                    if not is_v_home and is_command_message(prompt):
                        parse_result = parse_command(prompt, project_id, str(user_id) if user_id else None)
                        if parse_result.status in ("incomplete", "unknown"):
                            clarification_message = get_fallback_clarification(parse_result)
                            with st.chat_message("assistant", avatar=active_persona['icon']):
                                st.caption("üìå Ch·ªâ l·ªánh (@@) ‚Äî c·∫ßn l√†m r√µ")
                                st.info(clarification_message)
                            if st.session_state.get('enable_history', True):
                                try:
                                    services = init_services()
                                    supabase = services['supabase']
                                    supabase.table("chat_history").insert([
                                        {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "user", "content": prompt, "created_at": now_timestamp, "metadata": {"source": "command_fallback", "intent": "ask_user_clarification"}},
                                        {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "model", "content": f"[C·∫ßn l√†m r√µ] {clarification_message}", "created_at": now_timestamp, "metadata": {"intent": "ask_user_clarification"}},
                                    ]).execute()
                                    _after_save_history_v_work(project_id, user_id, active_persona.get("role", ""))
                                except Exception:
                                    pass
                            v7_handled = True
                        elif parse_result.status == "ok":
                            router_out = parse_result.parsed.router_out
                            debug_notes = ["üìå Ch·ªâ l·ªánh", f"Intent: {parse_result.parsed.intent}"]
                    if router_out is None:
                        semantic_match = None
                        try:
                            svc = init_services()
                            if svc:
                                r = svc["supabase"].table("settings").select("value").eq("key", "semantic_intent_no_use").execute()
                                no_use = r.data and r.data[0] and int(r.data[0].get("value", 0)) == 1
                                if not no_use:
                                    semantic_match = check_semantic_intent(prompt, project_id)
                        except Exception:
                            semantic_match = check_semantic_intent(prompt, project_id)
                    if router_out is None and semantic_match:
                        router_out = {"intent": "chat_casual", "target_files": [], "target_bible_entities": [], "rewritten_query": prompt, "chapter_range": None, "chapter_range_mode": None, "chapter_range_count": 5}
                        if semantic_match.get("related_data"):
                            router_out["_semantic_data"] = semantic_match["related_data"]
                        debug_notes.append(f"üéØ Semantic match {int(semantic_match.get('similarity',0)*100)}%")
                    elif router_out is None and not is_v_home and st.session_state.get('use_v7_planner', False):
                        plan_result = SmartAIRouter.get_plan_v7(prompt, recent_history_text, project_id)
                        plan = plan_result.get("plan") or []
                        first_intent = (plan[0].get("intent", "") if plan else "") or "chat_casual"
                        if first_intent == "ask_user_clarification":
                            clarification_question = (plan[0].get("args") or {}).get("clarification_question", "") or "B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n c√¢u h·ªèi ho·∫∑c ch·ªß ƒë·ªÅ b·∫°n mu·ªën h·ªèi?"
                            with st.chat_message("assistant", avatar=active_persona['icon']):
                                st.caption("üß† V7 Planner ‚Äî C·∫ßn l√†m r√µ")
                                st.info(f"**ƒê·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c, t√¥i c·∫ßn b·∫°n l√†m r√µ:**\n\n{clarification_question}")
                                st.text_input("B·∫°n c√≥ th·ªÉ g√µ l·∫°i ho·∫∑c b·ªï sung t·∫°i ƒë√¢y (g·ª≠i b·∫±ng √¥ chat ph√≠a d∆∞·ªõi):", key="clarification_followup", placeholder="V√≠ d·ª•: T√¥i mu·ªën h·ªèi v·ªÅ nh√¢n v·∫≠t A trong ch∆∞∆°ng 3")
                            if st.session_state.get('enable_history', True):
                                try:
                                    services = init_services()
                                    supabase = services['supabase']
                                    supabase.table("chat_history").insert([
                                        {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "user", "content": prompt, "created_at": now_timestamp, "metadata": {"intent": first_intent, "v7_plan": plan_result}},
                                        {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "model", "content": f"[C·∫ßn l√†m r√µ] {clarification_question}", "created_at": now_timestamp, "metadata": {"intent": first_intent}},
                                    ]).execute()
                                    if not is_v_home:
                                        _after_save_history_v_work(project_id, user_id, active_persona.get("role", ""))
                                except Exception:
                                    pass
                            v7_handled = True
                        elif first_intent == "update_data" and not is_v_home and can_write and (plan or []) and all((s.get("intent") or "") == "update_data" for s in (plan or [])):
                            # Ch·ªâ x·ª≠ l√Ω "ch·ªâ update_data" khi to√†n b·ªô plan l√† update_data; n·∫øu c√≥ b∆∞·ªõc kh√°c th√¨ ch·∫°y execute_plan b√™n d∆∞·ªõi.
                            data_steps = []
                            for s in (plan or []):
                                if (s.get("intent") or "") != "update_data":
                                    continue
                                a = s.get("args") or {}
                                t = (a.get("data_operation_target") or "").strip()
                                if t not in ("bible", "relation", "timeline", "chunking"):
                                    continue
                                op_type = a.get("data_operation_type") or "extract"
                                ch_range = a.get("chapter_range")
                                if ch_range and isinstance(ch_range, (list, tuple)) and len(ch_range) >= 2:
                                    try:
                                        start, end = int(ch_range[0]), int(ch_range[1])
                                        start, end = min(start, end), max(start, end)
                                        if start == end:
                                            data_steps.append({"operation_type": op_type, "target": t, "chapter_number": start})
                                        else:
                                            data_steps.append({"operation_type": op_type, "target": t, "chapter_range": [start, end]})
                                    except (ValueError, TypeError):
                                        if ch_range and len(ch_range) >= 1:
                                            data_steps.append({"operation_type": op_type, "target": t, "chapter_number": int(ch_range[0])})
                                elif ch_range and len(ch_range) >= 1:
                                    data_steps.append({"operation_type": op_type, "target": t, "chapter_number": int(ch_range[0])})
                                else:
                                    continue
                            if data_steps:
                                op_label_map = {"extract": "Tr√≠ch xu·∫•t", "update": "C·∫≠p nh·∫≠t", "delete": "X√≥a"}
                                target_label_map = {"bible": "Bible", "relation": "Relation", "timeline": "Timeline", "chunking": "Chunking"}
                                with st.chat_message("assistant", avatar=active_persona['icon']):
                                    st.caption("üß† V7 Planner ‚Äî update_data ‚Äî C·∫ßn x√°c nh·∫≠n (m·ªôt l·∫ßn cho t·∫•t c·∫£)")
                                    def _step_label(st):
                                    op = op_label_map.get(st.get('operation_type', ''), st.get('operation_type', ''))
                                    tg = target_label_map.get(st.get('target', ''), st.get('target', ''))
                                    if st.get("chapter_range") and len(st["chapter_range"]) >= 2:
                                        a, b = st["chapter_range"][0], st["chapter_range"][1]
                                        ch_str = f"ch∆∞∆°ng **{a}‚Äì{b}**" if a != b else f"ch∆∞∆°ng **{a}**"
                                    else:
                                        ch_str = f"ch∆∞∆°ng **{st.get('chapter_number', '')}**"
                                    return f"{op} **{tg}** {ch_str}"
                                if len(data_steps) == 1:
                                        st.info(
                                            f"**Y√™u c·∫ßu c·ªßa b·∫°n:** {prompt}\n\n"
                                            f"**Thao t√°c:** {_step_label(data_steps[0])}. "
                                            "B·∫°n c√≥ ch·∫•p nh·∫≠n k·∫øt qu·∫£ thao t√°c n√†y kh√¥ng? S·∫Ω ch·∫°y ng·∫ßm v√† xem nh∆∞ ƒë√£ ch·∫•p nh·∫≠n."
                                        )
                                    else:
                                        lines = [_step_label(st) for st in data_steps]
                                        st.info(
                                            f"**Y√™u c·∫ßu c·ªßa b·∫°n:** {prompt}\n\n**C√°c thao t√°c s·∫Ω th·ª±c hi·ªán ({len(data_steps)} b∆∞·ªõc):**\n" + "\n".join(f"- {line}" for line in lines) + "\n\nX√°c nh·∫≠n **m·ªôt l·∫ßn** ƒë·ªìng nghƒ©a b·∫°n ƒë·ªìng √Ω t·∫•t c·∫£. S·∫Ω ch·∫°y ng·∫ßm v√† xem nh∆∞ ƒë√£ ch·∫•p nh·∫≠n."
                                        )
                                if st.session_state.get('enable_history', True):
                                    try:
                                        services = init_services()
                                        supabase = services['supabase']
                                        model_msg = f"[C·∫ßn x√°c nh·∫≠n] {len(data_steps)} thao t√°c. X√°c nh·∫≠n m·ªôt l·∫ßn = ƒë·ªìng √Ω t·∫•t c·∫£. S·∫Ω ch·∫°y ng·∫ßm."
                                        supabase.table("chat_history").insert([
                                            {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "user", "content": prompt, "created_at": now_timestamp, "metadata": {"intent": first_intent, "v7_plan": plan_result}},
                                            {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "model", "content": model_msg, "created_at": now_timestamp, "metadata": {"intent": first_intent}},
                                        ]).execute()
                                        if not is_v_home:
                                            _after_save_history_v_work(project_id, user_id, active_persona.get("role", ""))
                                    except Exception:
                                        pass
                                st.session_state["pending_data_operation"] = {
                                    "project_id": project_id,
                                    "user_id": user_id,
                                    "user_request": prompt,
                                    "steps": data_steps,
                                }
                                v7_handled = True
                        if not v7_handled:
                            retries_used = 0
                            status_label = "V7 Multi-step"
                            with st.status(f"üìê {status_label}", expanded=True) as status:
                                st.write("üß† Planning...")
                                if plan_result.get("analysis"):
                                    st.caption(plan_result["analysis"][:500] + ("..." if len(plan_result.get("analysis", "")) > 500 else ""))
                                cumulative_context = ""
                                sources = []
                                step_results = []
                                replan_events = []
                                try:
                                    st.write(f"‚öôÔ∏è Executing {len(plan)} step(s)...")
                                    cumulative_context, sources, step_results, replan_events, data_operation_steps = execute_plan(
                                        plan,
                                        project_id,
                                        active_persona,
                                        prompt,
                                        st.session_state.get('strict_mode', False),
                                        st.session_state.get('current_arc_id'),
                                        dict(st.session_state),
                                        free_chat_mode=False,
                                        max_context_tokens=Config.CONTEXT_SIZE_TOKENS.get(st.session_state.get("context_size", "medium")),
                                        run_numerical_executor=True,
                                    )
                                    if data_operation_steps:
                                        st.session_state["pending_data_operation"] = {
                                            "project_id": project_id,
                                            "user_id": user_id,
                                            "user_request": prompt,
                                            "steps": data_operation_steps,
                                        }
                                    if replan_events:
                                        for ev in replan_events:
                                            st.caption(f"üîÑ Re-plan (sau step {ev.get('step_id')}): {ev.get('reason', '')[:80]}... ‚Üí {ev.get('action', '')}")
                                    st.write("üìù Generating draft...")
                                    system_content = (active_persona.get("system_prompt") or "") + "\n\n--- CONTEXT (C√°c b∆∞·ªõc ƒë√£ th·ª±c thi) ---\n" + cumulative_context
                                    user_content = prompt
                                    draft_resp = AIService.call_openrouter(
                                        messages=[
                                            {"role": "system", "content": system_content},
                                            {"role": "user", "content": user_content},
                                        ],
                                        model=st.session_state.get('selected_model', Config.DEFAULT_MODEL),
                                        temperature=0.0 if st.session_state.get('strict_mode') else 0.7,
                                        max_tokens=4096,
                                        stream=False,
                                    )
                                    draft_response = (draft_resp.choices[0].message.content or "").strip()
                                    st.write("üõ°Ô∏è Verifying...")
                                    verification_required = plan_result.get("verification_required", True)

                                    def _llm_generate(system_content: str, user_content: str) -> str:
                                        r = AIService.call_openrouter(
                                            messages=[
                                                {"role": "system", "content": system_content},
                                                {"role": "user", "content": user_content},
                                            ],
                                            model=st.session_state.get('selected_model', Config.DEFAULT_MODEL),
                                            temperature=0.0,
                                            max_tokens=4096,
                                            stream=False,
                                        )
                                        return (r.choices[0].message.content or "").strip()

                                    plan_for_verifier = [{"intent": r.get("intent", "chat_casual")} for r in step_results]
                                    final_response, retries_used = run_verification_loop(
                                        draft_response,
                                        cumulative_context,
                                        plan_for_verifier,
                                        step_results,
                                        _llm_generate,
                                        verification_required=verification_required,
                                    )
                                    if retries_used > 0:
                                        st.warning("‚ö†Ô∏è Detecting error, auto-correcting...")
                                    status.update(label=f"‚úÖ {status_label} ‚Äî Done", state="complete")
                                except Exception as ex:
                                    status.update(label=f"‚ùå {status_label} ‚Äî Error", state="error")
                                    final_response = f"L·ªói khi ch·∫°y V7: {ex}"
                                    import traceback
                                    st.exception(ex)

                            with st.chat_message("assistant", avatar=active_persona['icon']):
                                # Stream hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi cu·ªëi (typewriter effect)
                                _placeholder = st.empty()
                                import time
                                _chunk = 25
                                for _i in range(0, len(final_response), _chunk):
                                    _placeholder.markdown(final_response[:_i + _chunk] + "‚ñå")
                                    time.sleep(0.02)
                                _placeholder.markdown(final_response)
                                with st.expander("üìä V7 Details"):
                                    st.caption(f"Steps: {len(step_results)} | Verification retries: {retries_used}")
                                    if replan_events:
                                        st.caption("üîÑ Re-plan: " + "; ".join([f"Step {e.get('step_id')} ‚Üí {e.get('action')}" for e in replan_events]))
                                    st.json({
                                        "plan": plan_result.get("plan"),
                                        "verification_required": plan_result.get("verification_required"),
                                        "replan_events": replan_events,
                                    }, expanded=False)

                            if st.session_state.get('enable_history', True):
                                try:
                                    services = init_services()
                                    supabase = services['supabase']
                                    supabase.table("chat_history").insert([
                                        {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "user", "content": prompt, "created_at": now_timestamp, "metadata": {"v7": True, "plan": plan_result.get("plan")}},
                                        {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "model", "content": final_response, "created_at": now_timestamp, "metadata": {"v7": True, "verification_required": plan_result.get("verification_required")}},
                                    ]).execute()
                                    if not is_v_home:
                                        _after_save_history_v_work(project_id, user_id, active_persona.get("role", ""))
                                except Exception:
                                    pass
                            v7_handled = True
                    elif router_out is None:
                        router_out = SmartAIRouter.ai_router_pro_v2(prompt, recent_history_text, project_id)
                    if router_out is not None:
                        debug_notes = [f"Intent: {router_out.get('intent', 'chat_casual')}"] + debug_notes

                if not v7_handled:
                    intent = router_out.get('intent', 'chat_casual')
                    targets = router_out.get('target_files', [])
                    rewritten_query = router_out.get('rewritten_query', prompt)

                    # ask_user_clarification: d·ª´ng l·∫°i, hi·ªán popup h·ªèi user thay v√¨ g·ªçi LLM
                    if intent == "ask_user_clarification":
                        clarification_question = router_out.get("clarification_question", "") or "B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n c√¢u h·ªèi ho·∫∑c ch·ªß ƒë·ªÅ b·∫°n mu·ªën h·ªèi?"
                        with st.chat_message("assistant", avatar=active_persona['icon']):
                            st.caption("üß† Intent: ask_user_clarification ‚Äî C·∫ßn l√†m r√µ")
                            st.info(f"**ƒê·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c, t√¥i c·∫ßn b·∫°n l√†m r√µ:**\n\n{clarification_question}")
                            st.text_input("B·∫°n c√≥ th·ªÉ g√µ l·∫°i ho·∫∑c b·ªï sung t·∫°i ƒë√¢y (g·ª≠i b·∫±ng √¥ chat ph√≠a d∆∞·ªõi):", key="clarification_followup", placeholder="V√≠ d·ª•: T√¥i mu·ªën h·ªèi v·ªÅ nh√¢n v·∫≠t A trong ch∆∞∆°ng 3")
                        if st.session_state.get('enable_history', True):
                            try:
                                services = init_services()
                                supabase = services['supabase']
                                supabase.table("chat_history").insert([
                                    {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "user", "content": prompt, "created_at": now_timestamp, "metadata": {"intent": intent, "router_output": router_out}},
                                    {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "model", "content": f"[C·∫ßn l√†m r√µ] {clarification_question}", "created_at": now_timestamp, "metadata": {"intent": intent}},
                                ]).execute()
                                if not is_v_home:
                                    _after_save_history_v_work(project_id, user_id, active_persona.get("role", ""))
                            except Exception:
                                pass
                    elif intent == "suggest_v7":
                        reason = (router_out.get("reason") or "").strip()
                        with st.chat_message("assistant", avatar=active_persona['icon']):
                            st.caption("üß† V6 ‚Äî G·ª£i √Ω d√πng V7 Planner")
                            st.warning(get_v7_reminder_message())
                            if reason:
                                st.caption(f"*L√Ω do: {reason}*")
                        if st.session_state.get('enable_history', True):
                            try:
                                services = init_services()
                                supabase = services['supabase']
                                model_msg = "C√¢u h·ªèi c·∫ßn nhi·ªÅu b∆∞·ªõc x·ª≠ l√Ω (nhi·ªÅu intent ho·∫∑c nhi·ªÅu thao t√°c). Vui l√≤ng b·∫≠t V7 Planner ƒë·ªÉ th·ª±c hi·ªán ƒë·ªß trong m·ªôt l·∫ßn."
                                supabase.table("chat_history").insert([
                                    {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "user", "content": prompt, "created_at": now_timestamp, "metadata": {"intent": intent, "router_output": router_out}},
                                    {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "model", "content": model_msg, "created_at": now_timestamp, "metadata": {"intent": intent}},
                                ]).execute()
                                if not is_v_home:
                                    _after_save_history_v_work(project_id, user_id, active_persona.get("role", ""))
                            except Exception:
                                pass
                    elif intent == "update_data" and not is_v_home and can_write:
                        ch_range = router_out.get("chapter_range")
                        # @data_analyze: 4 b∆∞·ªõc (bible, relation, timeline, chunking)
                        if router_out.get("_data_analyze_full") and ch_range and len(ch_range) >= 2:
                            start, end = int(ch_range[0]), int(ch_range[1])
                            start, end = min(start, end), max(start, end)
                            data_steps = [
                                {"operation_type": "extract", "target": "bible", "chapter_range": [start, end]},
                                {"operation_type": "extract", "target": "relation", "chapter_range": [start, end]},
                                {"operation_type": "extract", "target": "timeline", "chapter_range": [start, end]},
                                {"operation_type": "extract", "target": "chunking", "chapter_range": [start, end]},
                            ]
                            with st.chat_message("assistant", avatar=active_persona['icon']):
                                st.caption("üìå Ch·ªâ l·ªánh @data_analyze ‚Äî C·∫ßn x√°c nh·∫≠n")
                                ch_str = f"ch∆∞∆°ng **{start}‚Äì{end}**" if start != end else f"ch∆∞∆°ng **{start}**"
                                st.info(f"**Y√™u c·∫ßu:** {prompt}\n\n**Thao t√°c (4 b∆∞·ªõc):** Tr√≠ch xu·∫•t Bible, Relation, Timeline, Chunking cho {ch_str}. X√°c nh·∫≠n m·ªôt l·∫ßn = ƒë·ªìng √Ω t·∫•t c·∫£.")
                                if st.session_state.get('enable_history', True):
                                    try:
                                        services = init_services()
                                        supabase = services['supabase']
                                        supabase.table("chat_history").insert([
                                            {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "user", "content": prompt, "created_at": now_timestamp, "metadata": {"intent": intent, "source": "command"}},
                                            {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "model", "content": "[C·∫ßn x√°c nh·∫≠n] 4 b∆∞·ªõc Data Analyze. S·∫Ω ch·∫°y ng·∫ßm.", "created_at": now_timestamp, "metadata": {"intent": intent}},
                                        ]).execute()
                                        _after_save_history_v_work(project_id, user_id, active_persona.get("role", ""))
                                    except Exception:
                                        pass
                                st.session_state["pending_data_operation"] = {
                                    "project_id": project_id,
                                    "user_id": user_id,
                                    "user_request": prompt,
                                    "steps": data_steps,
                                }
                        elif (router_out.get("data_operation_target") or "") in ("bible", "relation", "timeline", "chunking"):
                            op_type = router_out.get("data_operation_type") or "extract"
                            op_target = router_out.get("data_operation_target") or "bible"
                            ch_num = int(ch_range[0]) if (ch_range and len(ch_range) >= 1) else None
                            if ch_range and len(ch_range) >= 2:
                                start, end = int(ch_range[0]), int(ch_range[1])
                                ch_num = min(start, end)
                            op_label = {"extract": "Tr√≠ch xu·∫•t", "update": "C·∫≠p nh·∫≠t", "delete": "X√≥a"}.get(op_type, op_type)
                            target_label = {"bible": "Bible", "relation": "Relation", "timeline": "Timeline", "chunking": "Chunking"}.get(op_target, op_target)
                            if ch_num is None:
                                with st.chat_message("assistant", avatar=active_persona['icon']):
                                    st.caption("üß† Intent: update_data (thao t√°c theo ch∆∞∆°ng)")
                                    st.warning("Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c ch∆∞∆°ng. Vui l√≤ng n√≥i r√µ s·ªë ch∆∞∆°ng ho·∫∑c t√™n ch∆∞∆°ng (v√≠ d·ª•: ch∆∞∆°ng 1, ch∆∞∆°ng Kh·ªüi ƒë·∫ßu).")
                            else:
                                with st.chat_message("assistant", avatar=active_persona['icon']):
                                    st.caption("üß† Intent: update_data ‚Äî C·∫ßn x√°c nh·∫≠n")
                                    st.info(
                                        f"**Y√™u c·∫ßu c·ªßa b·∫°n:** {prompt}\n\n"
                                        f"**Thao t√°c:** {op_label} **{target_label}** cho ch∆∞∆°ng **{ch_num}**. "
                                        "B·∫°n c√≥ ch·∫•p nh·∫≠n k·∫øt qu·∫£ thao t√°c n√†y kh√¥ng? S·∫Ω ch·∫°y ng·∫ßm v√† xem nh∆∞ ƒë√£ ch·∫•p nh·∫≠n."
                                    )
                                if st.session_state.get('enable_history', True):
                                    try:
                                        services = init_services()
                                        supabase = services['supabase']
                                        model_msg = f"[C·∫ßn x√°c nh·∫≠n] {op_label} {target_label} ch∆∞∆°ng {ch_num}. B·∫°n c√≥ ch·∫•p nh·∫≠n k·∫øt qu·∫£ kh√¥ng? S·∫Ω ch·∫°y ng·∫ßm."
                                        supabase.table("chat_history").insert([
                                            {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "user", "content": prompt, "created_at": now_timestamp, "metadata": {"intent": intent, "router_output": router_out}},
                                            {"story_id": project_id, "user_id": str(user_id) if user_id else None, "role": "model", "content": model_msg, "created_at": now_timestamp, "metadata": {"intent": intent}},
                                        ]).execute()
                                        if not is_v_home:
                                            _after_save_history_v_work(project_id, user_id, active_persona.get("role", ""))
                                    except Exception:
                                        pass
                                st.session_state["pending_data_operation"] = {
                                    "project_id": project_id,
                                    "user_id": user_id,
                                    "user_request": prompt,
                                    "operation_type": op_type,
                                    "target": op_target,
                                    "chapter_number": ch_num,
                                }
                    else:
                        max_context_tokens = Config.CONTEXT_SIZE_TOKENS.get(st.session_state.get("context_size", "medium"))
                        exec_result = None
                        if intent == "numerical_calculation" and not free_chat_mode:
                            context_text, sources, context_tokens = ContextManager.build_context(
                                router_out, project_id, active_persona,
                                st.session_state.get('strict_mode', False),
                                current_arc_id=st.session_state.get('current_arc_id'),
                                session_state=dict(st.session_state),
                                max_context_tokens=max_context_tokens,
                            )
                            code_prompt = f"""User h·ªèi: "{prompt}"
Context c√≥ s·∫µn:
{context_text[:6000]}

Nhi·ªám v·ª•: T·∫°o code Python (pandas/numpy) ƒë·ªÉ tr·∫£ l·ªùi. G√°n k·∫øt qu·∫£ cu·ªëi v√†o bi·∫øn result.
Ch·ªâ tr·∫£ v·ªÅ code trong block ```python ... ```, kh√¥ng gi·∫£i th√≠ch."""
                            try:
                                code_resp = AIService.call_openrouter(
                                    messages=[{"role": "user", "content": code_prompt}],
                                    model=st.session_state.get('selected_model', Config.DEFAULT_MODEL),
                                    temperature=0.1,
                                    max_tokens=2000,
                                )
                                raw = (code_resp.choices[0].message.content or "").strip()
                                import re
                                m = re.search(r'```(?:python)?\s*(.*?)```', raw, re.DOTALL)
                                code = m.group(1).strip() if m else raw
                                if code:
                                    val, err = PythonExecutor.execute(code, result_variable="result")
                                    if err:
                                        exec_result = f"(Executor l·ªói: {err})"
                                    else:
                                        exec_result = str(val) if val is not None else "null"
                                        debug_notes.append("üßÆ Python Executor OK")
                            except Exception as ex:
                                exec_result = f"(L·ªói: {ex})"
                            if exec_result:
                                context_text += f"\n\n--- K·∫æT QU·∫¢ T√çNH TO√ÅN (Python Executor) ---\n{exec_result}"

                        if is_v_home:
                            context_text = "\n".join([
                                f"{m.get('role', 'user')}: {m.get('content', '')}"
                                for m in visible_msgs[-V_HOME_CONTEXT_MESSAGES:]
                            ])
                            sources = []
                        elif exec_result is None:
                            context_text, sources, context_tokens = ContextManager.build_context(
                                router_out,
                                project_id,
                                active_persona,
                                st.session_state.get('strict_mode', False),
                                current_arc_id=st.session_state.get('current_arc_id'),
                                session_state=dict(st.session_state),
                                free_chat_mode=free_chat_mode,
                                max_context_tokens=max_context_tokens,
                            )
                            if not free_chat_mode and router_out.get("_semantic_data"):
                                context_text = f"[SEMANTIC INTENT - Data]\n{router_out['_semantic_data']}\n\n{context_text}"
                                sources.append("üéØ Semantic Intent")

                        debug_notes.extend(sources)

                        final_prompt = f"CONTEXT:\n{context_text}\n\nUSER QUERY: {prompt}"

                        run_instruction = active_persona['core_instruction']
                        run_temperature = st.session_state.get('temperature', 0.7)

                        if st.session_state.get('strict_mode') and not free_chat_mode:
                            run_temperature = 0.0

                        messages = []
                        system_message = f"""{run_instruction}

            TH√îNG TIN NG·ªÆ C·∫¢NH (CONTEXT):
            {context_text}

            H∆Ø·ªöNG D·∫™N:
            - Tr·∫£ l·ªùi d·ª±a tr√™n Context n·∫øu c√≥.
            - H·ªØu √≠ch, s√∫c t√≠ch, ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ.
            - Ch·∫ø ƒë·ªô hi·ªán t·∫°i: {active_persona['role']}
            - Ng√¥n ng·ªØ: ∆Øu ti√™n Ti·∫øng Vi·ªát (tr·ª´ khi User y√™u c·∫ßu kh√°c ho·∫∑c code).
            """

                        messages.append({"role": "system", "content": system_message})

                        # Tr·∫£ l·ªùi ch·ªâ d·ª±a tr√™n context ƒë√£ thu th·∫≠p (Bible, ch∆∞∆°ng, timeline...); kh√¥ng nh·ªìi l·ªãch s·ª≠ chat v√†o LLM.
                        messages.append({"role": "user", "content": prompt})

                        try:
                            model = st.session_state.get('selected_model', Config.DEFAULT_MODEL)

                            response = AIService.call_openrouter(
                                messages=messages,
                                model=model,
                                temperature=run_temperature,
                                max_tokens=active_persona.get('max_tokens', 4000),
                                stream=True
                            )

                            with st.chat_message("assistant", avatar=active_persona['icon']):
                                if debug_notes:
                                    st.caption(f"üß† {', '.join(debug_notes)}")
                                if st.session_state.get('strict_mode'):
                                    st.caption("üîí Strict Mode: ON")

                                full_response_text = ""
                                placeholder = st.empty()

                                for chunk in response:
                                    if chunk.choices[0].delta.content is not None:
                                        content = chunk.choices[0].delta.content
                                        full_response_text += content
                                        placeholder.markdown(full_response_text + "‚ñå")

                                placeholder.markdown(full_response_text)

                            input_tokens = AIService.estimate_tokens(system_message + prompt)
                            output_tokens = AIService.estimate_tokens(full_response_text)
                            cost = AIService.calculate_cost(input_tokens, output_tokens, model)

                            if 'user' in st.session_state:
                                CostManager.update_budget(st.session_state.user.id, cost)

                            if full_response_text:
                                if is_v_home:
                                    topic_start = _v_home_get_current_topic_start(user_id)
                                    _v_home_save_message(user_id, "user", prompt, topic_start)
                                    _v_home_save_message(user_id, "model", full_response_text, topic_start)
                                elif st.session_state.get('enable_history', True):
                                    services = init_services()
                                    supabase = services['supabase']

                                    supabase.table("chat_history").insert([
                                        {
                                            "story_id": project_id,
                                            "user_id": str(user_id) if user_id else None,
                                            "role": "user",
                                            "content": prompt,
                                            "created_at": now_timestamp,
                                            "metadata": {
                                                "intent": intent,
                                                "router_output": router_out,
                                                "model": model,
                                                "temperature": run_temperature
                                            }
                                        },
                                        {
                                            "story_id": project_id,
                                            "user_id": str(user_id) if user_id else None,
                                            "role": "model",
                                            "content": full_response_text,
                                            "created_at": now_timestamp,
                                            "metadata": {
                                                "model": model,
                                                "cost": f"${cost:.6f}",
                                                "tokens": input_tokens + output_tokens
                                            }
                                        }
                                    ]).execute()

                                # update_data (ghi nh·ªõ quy t·∫Øc): l∆∞u pending x√°c nh·∫≠n tr∆∞·ªõc khi ghi Bible (ch·ªâ V Work; thao t√°c theo ch∆∞∆°ng x·ª≠ l√Ω ·ªü nh√°nh kh√°c)
                                op_t = (router_out.get("data_operation_target") or "").strip()
                                if not is_v_home and intent == "update_data" and can_write and op_t not in ("bible", "relation", "timeline", "chunking"):
                                    st.session_state["pending_update_confirm"] = {
                                        "project_id": project_id,
                                        "prompt": prompt,
                                        "response": full_response_text,
                                        "update_summary": router_out.get("update_summary", ""),
                                        "user_id": user_id,
                                    }

                                # V Work: tƒÉng counter crystallize v√† trigger n·∫øu >= 30 (reset v·ªÅ 0 sau crystallize)
                                if not is_v_home and can_write and user_id:
                                    _after_save_history_v_work(project_id, user_id, active_persona.get("role", ""))

                                # Rule mining (ch·ªâ V Work)
                                if not is_v_home and can_write:
                                    new_rule = RuleMiningSystem.extract_rule_raw(prompt, full_response_text)
                                    if new_rule:
                                        st.session_state['pending_new_rule'] = new_rule
                                    # Offer add to Semantic Intent (n·∫øu b·∫≠t auto-create v√† kh√¥ng ph·∫£i chat phi·∫øm)
                                    try:
                                        r = init_services()["supabase"].table("settings").select("value").eq("key", "semantic_intent_no_auto_create").execute()
                                        no_auto = r.data and r.data[0] and int(r.data[0].get("value", 0)) == 1
                                    except Exception:
                                        no_auto = False
                                    if not no_auto and intent != "chat_casual":
                                        st.session_state["pending_semantic_add"] = {"prompt": prompt, "response": full_response_text, "context": context_text, "intent": intent}

                            elif not st.session_state.get('enable_history', True):
                                st.caption("üëª Anonymous mode: History not saved & Rule mining disabled.")

                        except Exception as e:
                            st.error(f"Generation error: {str(e)}")

    with col_chat:
        _chat_messages_fragment()

    # Offer add to Semantic Intent (ch·ªâ V Work)
    if not is_v_home and "pending_semantic_add" in st.session_state and can_write:
        p = st.session_state["pending_semantic_add"]
        with st.expander("üéØ Th√™m v√†o Semantic Intent?", expanded=True):
            st.caption("C√¢u h·ªèi v·ª´a r·ªìi kh√¥ng ph·∫£i chat phi·∫øm. Th√™m l√†m m·∫´u ƒë·ªÉ l·∫ßn sau kh·ªõp nhanh?")
            st.write("**C√¢u h·ªèi:**", p.get("prompt", "")[:100])
            col_a, col_b = st.columns(2)
            with col_a:
                if st.button("‚úÖ Th√™m v√†o Semantic", key=f"chat_semantic_add_btn_{chat_mode}"):
                    def _add_semantic():
                        try:
                            svc = init_services()
                            if not svc:
                                return
                            sb = svc["supabase"]
                            vec = AIService.get_embedding(p.get("prompt", ""))
                            ctx = p.get("context", "") or ""
                            resp = p.get("response", "") or ""
                            related_data = (ctx.rstrip() + "\n\n--- C√¢u tr·∫£ l·ªùi ---\n" + resp) if ctx else resp
                            payload = {"story_id": project_id, "question_sample": p.get("prompt", ""), "intent": "chat_casual", "related_data": related_data}
                            if vec:
                                payload["embedding"] = vec
                            try:
                                sb.table("semantic_intent").insert(payload).execute()
                            except Exception:
                                payload.pop("embedding", None)
                                sb.table("semantic_intent").insert(payload).execute()
                        except Exception:
                            pass
                    threading.Thread(target=_add_semantic, daemon=True).start()
                    del st.session_state["pending_semantic_add"]
                    st.toast("ƒê√£ th√™m v√†o Semantic Intent (ch·∫°y ng·∫ßm).")
                    st.rerun()
            with col_b:
                if st.button("‚ùå B·ªè qua", key=f"chat_semantic_skip_btn_{chat_mode}"):
                    del st.session_state["pending_semantic_add"]
                    st.rerun()

    # data_operation: X√°c nh·∫≠n th·ª±c hi·ªán thao t√°c (m·ªôt ho·∫∑c nhi·ªÅu b∆∞·ªõc) ‚Äî ch·∫°y ng·∫ßm, xong g·ª≠i tin nh·∫Øn (ch·ªâ V Work)
    if not is_v_home and "pending_data_operation" in st.session_state and can_write:
        pdo = st.session_state["pending_data_operation"]
        if pdo.get("project_id") == project_id:
            steps = pdo.get("steps")
            is_batch = isinstance(steps, list) and len(steps) > 0
            with st.expander("üì¶ X√°c nh·∫≠n th·ª±c hi·ªán thao t√°c d·ªØ li·ªáu?", expanded=True):
                st.caption("Thao t√°c s·∫Ω ch·∫°y ng·∫ßm v√† xem nh∆∞ b·∫°n ƒë√£ ch·∫•p nh·∫≠n k·∫øt qu·∫£. Khi xong s·∫Ω c√≥ tin nh·∫Øn trong chat.")
                st.write("**Y√™u c·∫ßu:**", pdo.get("user_request", "")[:200])
                if is_batch:
                    st.write("**S·ªë b∆∞·ªõc (logic):**", len(steps))
                    for i, st in enumerate(steps[:10]):
                        if st.get("chapter_range") and len(st.get("chapter_range", [])) >= 2:
                            a, b = st["chapter_range"][0], st["chapter_range"][1]
                            ch_display = f"{a}‚Äì{b}" if a != b else str(a)
                        else:
                            ch_display = st.get('chapter_number', '')
                        st.write(f"- {st.get('operation_type', '')} {st.get('target', '')} ‚Äî ch∆∞∆°ng {ch_display}")
                    if len(steps) > 10:
                        st.caption(f"... v√† {len(steps) - 10} b∆∞·ªõc kh√°c.")
                else:
                    st.write("**Thao t√°c:**", pdo.get("operation_type", ""), pdo.get("target", ""), "‚Äî ch∆∞∆°ng", pdo.get("chapter_number", ""))
                col_ok, col_no = st.columns(2)
                with col_ok:
                    if st.button("‚úÖ X√°c nh·∫≠n th·ª±c hi·ªán", key=f"data_op_confirm_ok_{chat_mode}"):
                        try:
                            import threading
                            if is_batch:
                                from core.data_operation_jobs import run_data_operations_batch
                                threading.Thread(
                                    target=run_data_operations_batch,
                                    kwargs={
                                        "project_id": pdo["project_id"],
                                        "user_id": pdo.get("user_id"),
                                        "steps": steps,
                                        "user_request": pdo["user_request"],
                                    },
                                    daemon=True,
                                ).start()
                            else:
                                from core.data_operation_jobs import run_data_operation
                                threading.Thread(
                                    target=run_data_operation,
                                    kwargs={
                                        "project_id": pdo["project_id"],
                                        "user_id": pdo.get("user_id"),
                                        "operation_type": pdo["operation_type"],
                                        "target": pdo["target"],
                                        "chapter_number": pdo["chapter_number"],
                                        "user_request": pdo["user_request"],
                                    },
                                    daemon=True,
                                ).start()
                            services = init_services()
                            if services and st.session_state.get('enable_history', True):
                                supabase = services["supabase"]
                                now_ts = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%S.%f")[:-3] + "Z"
                                supabase.table("chat_history").insert({
                                    "story_id": project_id,
                                    "user_id": str(pdo.get("user_id")) if pdo.get("user_id") else None,
                                    "role": "model",
                                    "content": "ƒê√£ ch·∫•p nh·∫≠n. ƒêang th·ª±c hi·ªán y√™u c·∫ßu c·ªßa b·∫°n (ch·∫°y ng·∫ßm). Khi xong s·∫Ω c√≥ tin nh·∫Øn ti·∫øp theo." + (" (" + str(len(steps)) + " b∆∞·ªõc)" if is_batch else ""),
                                    "created_at": now_ts,
                                    "metadata": {"data_operation_accepted": True, "batch": is_batch},
                                }).execute()
                            del st.session_state["pending_data_operation"]
                            st.toast("ƒê√£ ch·∫•p nh·∫≠n. Thao t√°c ƒëang ch·∫°y ng·∫ßm." + (" (" + str(len(steps)) + " b∆∞·ªõc)" if is_batch else ""))
                            st.rerun()
                        except Exception as e:
                            st.error(f"L·ªói: {e}")
                with col_no:
                    if st.button("‚ùå H·ªßy", key=f"data_op_confirm_no_{chat_mode}"):
                        del st.session_state["pending_data_operation"]
                        st.rerun()

    # update_data: X√°c nh·∫≠n cu·ªëi c√πng tr∆∞·ªõc khi ghi Bible / c·∫≠p nh·∫≠t (ch·ªâ V Work)
    if not is_v_home and "pending_update_confirm" in st.session_state and can_write:
        pu = st.session_state["pending_update_confirm"]
        if pu.get("project_id") == project_id:
            with st.expander("‚úèÔ∏è X√°c nh·∫≠n th·ª±c hi·ªán c·∫≠p nh·∫≠t?", expanded=True):
                st.caption("B·∫°n ƒë√£ y√™u c·∫ßu ghi nh·ªõ / c·∫≠p nh·∫≠t d·ªØ li·ªáu. Ch·ªâ th·ª±c hi·ªán khi b·∫°n x√°c nh·∫≠n.")
                st.write("**T√≥m t·∫Øt:**", pu.get("update_summary", "") or "(Theo n·ªôi dung AI tr·∫£ l·ªùi)")
                st.write("**N·ªôi dung s·∫Ω ghi:**", (pu.get("response", "") or "")[:500])
                col_ok, col_no = st.columns(2)
                with col_ok:
                    if st.button("‚úÖ X√°c nh·∫≠n th·ª±c hi·ªán", key=f"update_confirm_ok_{chat_mode}"):
                        try:
                            services = init_services()
                            supabase = services["supabase"]
                            content_to_save = (pu.get("response", "") or pu.get("update_summary", "") or "").strip()
                            if content_to_save:
                                vec = AIService.get_embedding(content_to_save[:8000])
                                payload = {
                                    "story_id": project_id,
                                    "entity_name": f"[RULE] {datetime.now().strftime('%Y%m%d_%H%M%S')}",
                                    "description": content_to_save,
                                    "source_chapter": 0,
                                }
                                if vec:
                                    payload["embedding"] = vec
                                supabase.table("story_bible").insert(payload).execute()
                                st.toast("ƒê√£ ghi nh·ªõ / c·∫≠p nh·∫≠t v√†o Bible.")
                            del st.session_state["pending_update_confirm"]
                            st.rerun()
                        except Exception as e:
                            st.error(f"L·ªói khi ghi: {e}")
                with col_no:
                    if st.button("‚ùå H·ªßy", key=f"update_confirm_no_{chat_mode}"):
                        del st.session_state["pending_update_confirm"]
                        st.rerun()

    # Rule Mining UI (ch·ªâ V Work; V Home kh√¥ng nh·∫≠n di·ªán / add rule)
    if not is_v_home and 'pending_new_rule' in st.session_state and can_write:
        rule_content = st.session_state['pending_new_rule']

        with st.expander("üßê AI discovered a new Rule!", expanded=True):
            st.caption("Rule l∆∞u v√†o **Knowledge > Bible** (prefix [RULE]).")
            st.write(f"**Content:** {rule_content}")

            if st.session_state.get('rule_analysis') is None:
                with st.spinner("Checking for conflicts..."):
                    st.session_state['rule_analysis'] = RuleMiningSystem.analyze_rule_conflict(rule_content, project_id)

            analysis = st.session_state['rule_analysis']
            if analysis:
                st.info(f"AI Assessment: **{analysis.get('status', 'UNKNOWN')}** - {analysis.get('reason', 'N/A')}")
                if analysis['status'] == "CONFLICT":
                    st.warning(f"‚ö†Ô∏è Conflict with: {analysis['existing_rule_summary']}")
                elif analysis['status'] == "MERGE":
                    st.info(f"üí° Merge suggestion: {analysis['merged_content']}")
            else:
                st.error("Could not analyze rule conflict.")

            c1, c2, c3 = st.columns(3)

            if c1.button("‚úÖ Save/Merge Rule", key=f"rule_save_btn_{chat_mode}"):
                final_content = analysis.get('merged_content') if analysis and analysis['status'] == "MERGE" else rule_content
                vec = AIService.get_embedding(final_content)

                services = init_services()
                supabase = services['supabase']

                payload = {
                    "entity_name": f"[RULE] {datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "description": final_content,
                    "embedding": vec,
                    "source_chapter": 0,
                }
                try:
                    if can_write:
                        payload["story_id"] = project_id
                        supabase.table("story_bible").insert(payload).execute()
                        st.toast("Learned new rule!")
                    elif can_request:
                        pid = submit_pending_change(
                            story_id=project_id,
                            requested_by_email=user_email or "",
                            table_name="story_bible",
                            target_key={},
                            old_data={},
                            new_data=payload,
                        )
                        if pid:
                            st.toast("ƒê√£ g·ª≠i y√™u c·∫ßu th√™m RULE cho Owner duy·ªát.", icon="üì§")
                        else:
                            st.error("Kh√¥ng g·ª≠i ƒë∆∞·ª£c y√™u c·∫ßu (ki·ªÉm tra b·∫£ng pending_changes).")
                    else:
                        st.warning("B·∫°n kh√¥ng c√≥ quy·ªÅn l∆∞u ho·∫∑c g·ª≠i y√™u c·∫ßu Rule.")
                except Exception as e:
                    st.error(f"L·ªói khi l∆∞u RULE: {e}")

                del st.session_state['pending_new_rule']
                del st.session_state['rule_analysis']
                st.rerun()

            if c2.button("‚úèÔ∏è Edit then Save", key=f"rule_edit_btn_{chat_mode}"):
                st.session_state['edit_rule_manual'] = rule_content

            if c3.button("‚ùå Ignore", key=f"rule_ignore_btn_{chat_mode}"):
                del st.session_state['pending_new_rule']
                del st.session_state['rule_analysis']
                st.rerun()

        if not is_v_home and 'edit_rule_manual' in st.session_state and can_write:
            edited = st.text_input("Edit rule:", value=st.session_state['edit_rule_manual'], key=f"edit_rule_input_{chat_mode}")
            if st.button("Save edited version", key=f"rule_save_edited_btn_{chat_mode}"):
                vec = AIService.get_embedding(edited)

                services = init_services()
                supabase = services['supabase']

                supabase.table("story_bible").insert({
                    "story_id": project_id,
                    "entity_name": "[RULE] Manual",
                    "description": edited,
                    "embedding": vec,
                    "source_chapter": 0
                }).execute()

                del st.session_state['pending_new_rule']
                del st.session_state['rule_analysis']
                del st.session_state['edit_rule_manual']
                st.rerun()
