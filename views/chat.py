from datetime import datetime

import streamlit as st

from config import Config, init_services, CostManager
from ai_engine import (
    AIService,
    ContextManager,
    SmartAIRouter,
    RuleMiningSystem,
)
from persona import PersonaSystem


def render_chat_tab(project_id, persona):
    """Tab Chat - AI Conversation v·ªõi t√≠nh nƒÉng n√¢ng cao. Persona c√≥ th·ªÉ ch·ªçn l·∫°i trong tab."""
    st.header("üí¨ Smart AI Chat")

    col_chat, col_memory = st.columns([3, 1])

    with col_memory:
        st.write("### üß† Memory & Settings")
        available = PersonaSystem.get_available_personas()
        default_key = st.session_state.get("persona", "Writer")
        idx = available.index(default_key) if default_key in available else 0
        selected_persona_key = st.selectbox(
            "Persona tr·∫£ l·ªùi",
            available,
            index=idx,
            key="chat_persona_key",
            help="Ch·ªçn persona ƒë·ªÉ AI tr·∫£ l·ªùi theo phong c√°ch n√†y."
        )
        active_persona = PersonaSystem.get_persona(selected_persona_key)

        if st.button("üßπ Clear Screen", use_container_width=True):
            st.session_state['chat_cutoff'] = datetime.utcnow().isoformat()
            st.rerun()

        if st.button("üîÑ Show All", use_container_width=True):
            st.session_state['chat_cutoff'] = "1970-01-01"
            st.rerun()

        st.session_state['enable_history'] = st.toggle(
            "üíæ Save Chat History",
            value=True,
            help="Turn off for anonymous chat (Not saved to DB, AI doesn't learn)"
        )

        st.session_state['strict_mode'] = st.toggle(
            "üö´ Strict Mode",
            value=False,
            help="ON: AI only answers based on found data. No fabrication. (Temp = 0)"
        )
        st.session_state['router_ignore_history'] = st.toggle(
            "‚ö°Ô∏è Router Ignore History",
            value=False,
            help="B·∫≠t c√°i n√†y ƒë·ªÉ Router ch·ªâ ph√¢n t√≠ch c√¢u hi·ªán t·∫°i, kh√¥ng b·ªã nhi·ªÖu b·ªüi chat c≈©."
        )
        st.divider()
        st.write("### üï∞Ô∏è Context Depth")
        st.session_state["history_depth"] = st.slider(
            "Chat History Limit",
            min_value=0,
            max_value=30,
            value=st.session_state.get("history_depth", 5),
            step=1,
            help="S·ªë l∆∞·ª£ng tin nh·∫Øn c≈© g·ª≠i k√®m. C√†ng cao c√†ng nh·ªõ dai nh∆∞ng t·ªën ti·ªÅn h∆°n.",
            key="chat_history_depth",
        )

        with st.expander("üíé Crystallize Chat"):
            st.caption("Save key points to Bible.")
            crys_option = st.radio("Scope:", ["Last 20 messages", "Entire session"])
            memory_topic = st.text_input("Topic:", placeholder="e.g., Magic System")

            if st.button("‚ú® Crystallize"):
                services = init_services()
                supabase = services['supabase']

                limit = 20 if crys_option == "Last 20 messages" else 100
                chat_data = supabase.table("chat_history") \
                    .select("*") \
                    .eq("story_id", project_id) \
                    .order("created_at", desc=True) \
                    .limit(limit) \
                    .execute()

                if chat_data.data:
                    chat_data.data.reverse()
                    with st.spinner("Summarizing..."):
                        summary = RuleMiningSystem.crystallize_session(chat_data.data, active_persona['role'])
                        if summary != "NO_INFO":
                            st.session_state['chat_crystallized_summary'] = summary
                            st.session_state['chat_crystallized_topic'] = memory_topic if memory_topic else f"Chat {datetime.now().strftime('%d/%m')}"
                            st.success("Summary ready!")
                        else:
                            st.warning("No valuable information found.")

        if 'chat_crystallized_summary' in st.session_state:
            final_sum = st.text_area("Edit summary:", value=st.session_state['chat_crystallized_summary'])
            if st.button("üíæ Save to Memory"):
                vec = AIService.get_embedding(final_sum)
                if vec:
                    services = init_services()
                    supabase = services['supabase']

                    supabase.table("story_bible").insert({
                        "story_id": project_id,
                        "entity_name": f"[CHAT] {st.session_state['chat_crystallized_topic']}",
                        "description": final_sum,
                        "embedding": vec,
                        "source_chapter": 0
                    }).execute()

                    st.toast("Saved to memory!")
                    del st.session_state['chat_crystallized_summary']
                    st.rerun()

    @st.fragment
    def _chat_messages_fragment():
        try:
            services = init_services()
            supabase = services["supabase"]
            msgs_data = supabase.table("chat_history").select("*").eq("story_id", project_id).order("created_at", desc=True).limit(50).execute()
            msgs = msgs_data.data[::-1] if msgs_data.data else []
            visible_msgs = [m for m in msgs if m["created_at"] > st.session_state.get("chat_cutoff", "1970-01-01")]
            for m in visible_msgs:
                role_icon = active_persona["icon"] if m["role"] == "model" else None
                with st.chat_message(m["role"], avatar=role_icon):
                    st.markdown(m["content"])
                    if m.get("metadata"):
                        with st.expander("üìä Details"):
                            st.json(m["metadata"], expanded=False)
        except Exception as e:
            st.error(f"Error loading history: {e}")
        history_depth = st.session_state.get("history_depth", 5)
        if prompt := st.chat_input(f"Ask {active_persona['icon']} AI Assistant...", key="chat_input_main"):
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.spinner("Thinking..."):
                now_timestamp = datetime.utcnow().isoformat()

                if st.session_state.get('router_ignore_history'):
                    recent_history_text = "NO_HISTORY_AVAILABLE (User requested to ignore context)"
                else:
                    recent_history_text = "\n".join([
                        f"{m['role']}: {m['content']}"
                        for m in visible_msgs[-5:]
                    ])

                router_out = SmartAIRouter.ai_router_pro_v2(prompt, recent_history_text, project_id)
                intent = router_out.get('intent', 'chat_casual')
                targets = router_out.get('target_files', [])
                rewritten_query = router_out.get('rewritten_query', prompt)

                debug_notes = [f"Intent: {intent}"]
                if st.session_state.get('router_ignore_history'):
                    debug_notes.append("‚ö°Ô∏è Router: Ignored History")

                context_text, sources, context_tokens = ContextManager.build_context(
                    router_out,
                    project_id,
                    active_persona,
                    st.session_state.get('strict_mode', False)
                )

                debug_notes.extend(sources)

                final_prompt = f"CONTEXT:\n{context_text}\n\nUSER QUERY: {prompt}"

                run_instruction = active_persona['core_instruction']
                run_temperature = st.session_state.get('temperature', 0.7)

                if st.session_state.get('strict_mode'):
                    run_temperature = 0.0

                messages = []
                system_message = f"""{run_instruction}

            TH√îNG TIN NG·ªÆ C·∫¢NH (CONTEXT):
            {context_text}

            H∆Ø·ªöNG D·∫™N:
            - Tr·∫£ l·ªùi d·ª±a tr√™n Context n·∫øu c√≥.
            - H·ªØu √≠ch, s√∫c t√≠ch, ƒëi th·∫≥ng v√†o v·∫•n ƒë·ªÅ.
            - Ch·∫ø ƒë·ªô hi·ªán t·∫°i: {active_persona['role']}
            - Ng√¥n ng·ªØ: ∆Øu ti√™n Ti·∫øng Vi·ªát (tr·ª´ khi User y√™u c·∫ßu kh√°c ho·∫∑c code).
            """

                messages.append({"role": "system", "content": system_message})

                depth = history_depth
                if depth > 0:
                    past_chats = visible_msgs[-depth:]
                else:
                    past_chats = []

                for msg in past_chats:
                    messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })

                if len(past_chats) > 5:
                    debug_notes.append(f"üìö Memory: Last {len(past_chats)} msgs")

                messages.append({"role": "user", "content": prompt})

                try:
                    model = st.session_state.get('selected_model', Config.DEFAULT_MODEL)

                    response = AIService.call_openrouter(
                        messages=messages,
                        model=model,
                        temperature=run_temperature,
                        max_tokens=active_persona.get('max_tokens', 4000),
                        stream=True
                    )

                    with st.chat_message("assistant", avatar=active_persona['icon']):
                        if debug_notes:
                            st.caption(f"üß† {', '.join(debug_notes)}")
                        if st.session_state.get('strict_mode'):
                            st.caption("üîí Strict Mode: ON")

                        full_response_text = ""
                        placeholder = st.empty()

                        for chunk in response:
                            if chunk.choices[0].delta.content is not None:
                                content = chunk.choices[0].delta.content
                                full_response_text += content
                                placeholder.markdown(full_response_text + "‚ñå")

                        placeholder.markdown(full_response_text)

                    input_tokens = AIService.estimate_tokens(system_message + prompt)
                    output_tokens = AIService.estimate_tokens(full_response_text)
                    cost = AIService.calculate_cost(input_tokens, output_tokens, model)

                    if 'user' in st.session_state:
                        CostManager.update_budget(st.session_state.user.id, cost)

                    if full_response_text and st.session_state.get('enable_history', True):
                        services = init_services()
                        supabase = services['supabase']

                        supabase.table("chat_history").insert([
                            {
                                "story_id": project_id,
                                "role": "user",
                                "content": prompt,
                                "created_at": now_timestamp,
                                "metadata": {
                                    "intent": intent,
                                    "router_output": router_out,
                                    "model": model,
                                    "temperature": run_temperature
                                }
                            },
                            {
                                "story_id": project_id,
                                "role": "model",
                                "content": full_response_text,
                                "created_at": now_timestamp,
                                "metadata": {
                                    "model": model,
                                    "cost": f"${cost:.6f}",
                                    "tokens": input_tokens + output_tokens
                                }
                            }
                        ]).execute()

                        new_rule = RuleMiningSystem.extract_rule_raw(prompt, full_response_text)
                        if new_rule:
                            st.session_state['pending_new_rule'] = new_rule

                    elif not st.session_state.get('enable_history', True):
                        st.caption("üëª Anonymous mode: History not saved & Rule mining disabled.")

                except Exception as e:
                    st.error(f"Generation error: {str(e)}")

    with col_chat:
        _chat_messages_fragment()

    if 'pending_new_rule' in st.session_state:
        rule_content = st.session_state['pending_new_rule']

        with st.expander("üßê AI discovered a new Rule!", expanded=True):
            st.write(f"**Content:** {rule_content}")

            if st.session_state.get('rule_analysis') is None:
                with st.spinner("Checking for conflicts..."):
                    st.session_state['rule_analysis'] = RuleMiningSystem.analyze_rule_conflict(rule_content, project_id)

            analysis = st.session_state['rule_analysis']
            if analysis:
                st.info(f"AI Assessment: **{analysis.get('status', 'UNKNOWN')}** - {analysis.get('reason', 'N/A')}")
                if analysis['status'] == "CONFLICT":
                    st.warning(f"‚ö†Ô∏è Conflict with: {analysis['existing_rule_summary']}")
                elif analysis['status'] == "MERGE":
                    st.info(f"üí° Merge suggestion: {analysis['merged_content']}")
            else:
                st.error("Could not analyze rule conflict.")

            c1, c2, c3 = st.columns(3)

            if c1.button("‚úÖ Save/Merge Rule"):
                final_content = analysis.get('merged_content') if analysis and analysis['status'] == "MERGE" else rule_content
                vec = AIService.get_embedding(final_content)

                services = init_services()
                supabase = services['supabase']

                supabase.table("story_bible").insert({
                    "story_id": project_id,
                    "entity_name": f"[RULE] {datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "description": final_content,
                    "embedding": vec,
                    "source_chapter": 0
                }).execute()

                st.toast("Learned new rule!")
                del st.session_state['pending_new_rule']
                del st.session_state['rule_analysis']
                st.rerun()

            if c2.button("‚úèÔ∏è Edit then Save"):
                st.session_state['edit_rule_manual'] = rule_content

            if c3.button("‚ùå Ignore"):
                del st.session_state['pending_new_rule']
                del st.session_state['rule_analysis']
                st.rerun()

        if 'edit_rule_manual' in st.session_state:
            edited = st.text_input("Edit rule:", value=st.session_state['edit_rule_manual'])
            if st.button("Save edited version"):
                vec = AIService.get_embedding(edited)

                services = init_services()
                supabase = services['supabase']

                supabase.table("story_bible").insert({
                    "story_id": project_id,
                    "entity_name": "[RULE] Manual",
                    "description": edited,
                    "embedding": vec,
                    "source_chapter": 0
                }).execute()

                del st.session_state['pending_new_rule']
                del st.session_state['rule_analysis']
                del st.session_state['edit_rule_manual']
                st.rerun()
