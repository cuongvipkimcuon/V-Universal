import streamlit as st
import google.generativeai as genai
from supabase import create_client, Client
import json
import re
import pandas as pd
import time
from datetime import datetime
import extra_streamlit_components as stx
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from google.api_core.exceptions import ResourceExhausted, DeadlineExceeded, ServiceUnavailable
from persona import PERSONAS

# ==========================================
# üé® 1. C·∫§U H√åNH & CSS
# ==========================================
st.set_page_config(page_title="V-Universe Hub", page_icon="üåå", layout="wide")

st.markdown("""
<style>
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] { height: 50px; background-color: #f0f2f6; border-radius: 5px; }
    .stTabs [aria-selected="true"] { background-color: #ff4b4b; color: white; }
    div[data-testid="stExpander"] { background-color: #f8f9fa; border-radius: 10px; border: 1px solid #ddd; }
</style>
""", unsafe_allow_html=True)

# TH√ÅO X√çCH AN TO√ÄN
SAFE_CONFIG = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}
MODEL_PRIORITY = ["gemini-3-flash-preview","gemini-2.5-flash", "gemini-2.0-flash"]

# --- 2. KH·ªûI T·∫†O K·∫æT N·ªêI (AN TO√ÄN) ---
def init_services():
    try:
        SUPABASE_URL = st.secrets["supabase"]["SUPABASE_URL"]
        SUPABASE_KEY = st.secrets["supabase"]["SUPABASE_KEY"]
        GEMINI_KEY = st.secrets["gemini"]["API_KEY"]
        
        client = create_client(SUPABASE_URL, SUPABASE_KEY)
        genai.configure(api_key=GEMINI_KEY)
        return client
    except Exception as e:
        return None

supabase = init_services()

if not supabase:
    st.error("‚ùå L·ªói k·∫øt n·ªëi! Ki·ªÉm tra l·∫°i file secrets.toml")
    st.stop()

# --- 3. COOKIE MANAGER & LOGIN ---
cookie_manager = stx.CookieManager()

def check_login_status():
    if 'user' not in st.session_state:
        if 'cookie_check_done' not in st.session_state:
            with st.spinner("‚è≥ ƒêang l·ª•c l·ªçi k√Ω ·ª©c (Ch·ªù 3s)..."):
                time.sleep(3) 
                access_token = cookie_manager.get("supabase_access_token")
                refresh_token = cookie_manager.get("supabase_refresh_token")
                
                if access_token and refresh_token:
                    try:
                        session = supabase.auth.set_session(access_token, refresh_token)
                        if session:
                            st.session_state.user = session.user
                            st.toast("üëã M·ª´ng √¥ng gi√°o tr·ªü l·∫°i!", icon="üç™")
                            st.rerun() 
                    except: pass
                st.session_state['cookie_check_done'] = True
                st.rerun()

    if 'user' not in st.session_state:
        st.title("üîê ƒêƒÉng nh·∫≠p V-Brainer")
        col_main, _ = st.columns([1, 1])
        with col_main:
            email = st.text_input("Email")
            password = st.text_input("M·∫≠t kh·∫©u", type="password")
            
            c1, c2 = st.columns(2)
            if c1.button("ƒêƒÉng Nh·∫≠p", type="primary", use_container_width=True):
                try:
                    res = supabase.auth.sign_in_with_password({"email": email, "password": password})
                    st.session_state.user = res.user
                    cookie_manager.set("supabase_access_token", res.session.access_token, key="set_access")
                    cookie_manager.set("supabase_refresh_token", res.session.refresh_token, key="set_refresh")
                    st.success("ƒêƒÉng nh·∫≠p th√†nh c√¥ng!")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"L·ªói: {e}")
            if c2.button("ƒêƒÉng K√Ω", use_container_width=True):
                try:
                    res = supabase.auth.sign_up({"email": email, "password": password})
                    st.session_state.user = res.user
                    if res.session:
                        cookie_manager.set("supabase_access_token", res.session.access_token, key="set_acc_up")
                        cookie_manager.set("supabase_refresh_token", res.session.refresh_token, key="set_ref_up")
                    st.success("T·∫°o user th√†nh c√¥ng!")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"L·ªói: {e}")
        st.stop() 

check_login_status()

# --- SIDEBAR ---
with st.sidebar:
    st.info(f"üë§ {st.session_state.user.email}")
    if st.button("üö™ ƒêƒÉng xu·∫•t", use_container_width=True):
        supabase.auth.sign_out()
        cookie_manager.delete("supabase_access_token")
        cookie_manager.delete("supabase_refresh_token")
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

# ==========================================
# üß† 4. CORE AI LOGIC
# ==========================================
def generate_content_with_fallback(prompt, system_instruction, stream=True):
    for model_name in MODEL_PRIORITY:
        try:
            model = genai.GenerativeModel(model_name, system_instruction=system_instruction)
            response = model.generate_content(
                prompt, safety_settings=SAFE_CONFIG, stream=stream, request_options={'timeout': 60}
            )
            return response
        except Exception as e: continue
    raise Exception("All models failed")

def get_embedding(text):
    # Ki·ªÉm tra an to√†n ƒë·ªÉ tr√°nh ValueError khi text r·ªóng
    if not text or not isinstance(text, str) or not text.strip():
        # Tr·∫£ v·ªÅ None ho·∫∑c raise l·ªói c√≥ ki·ªÉm so√°t
        return None 
    return genai.embed_content(model="models/text-embedding-004", content=text, task_type="retrieval_document")['embedding']

def smart_search_hybrid(query_text, project_id, top_k=10):
    try:
        query_vec = get_embedding(query_text)
        if not query_vec: return "" # N·∫øu kh√¥ng embed ƒë∆∞·ª£c th√¨ tr·∫£ v·ªÅ r·ªóng
        
        response = supabase.rpc("hybrid_search", {
            "query_text": query_text, 
            "query_embedding": query_vec,
            "match_threshold": 0.3, "match_count": top_k, "story_id_input": project_id
        }).execute()
        results = []
        if response.data:
            for item in response.data:
                results.append(f"- [{item['entity_name']}]: {item['description']}")
        return "\n".join(results) if results else ""
    except: return ""

def ai_router_pro(user_prompt):
    router_prompt = f"""
    Ph√¢n t√≠ch User Prompt v√† tr·∫£ v·ªÅ JSON:
    1. "intent": "search_bible" OR "chat_casual".
    2. "target_chapter": S·ªë File c·∫ßn ƒë·ªçc (Int/Null).
    USER: "{user_prompt}"
    JSON OUTPUT ONLY.
    """
    try:
        model = genai.GenerativeModel("gemini-2.5-flash")
        res = model.generate_content(router_prompt, generation_config={"response_mime_type": "application/json"})
        return json.loads(res.text)
    except: return {"intent": "chat_casual", "target_chapter": None}

def crystallize_session(chat_history, persona_role):
    chat_text = "\n".join([f"{m['role']}: {m['content']}" for m in chat_history])
    crystallize_prompt = f"""
    B·∫°n l√† Th∆∞ K√Ω Ghi Ch√©p ({persona_role}).
    Nhi·ªám v·ª•: ƒê·ªçc ƒëo·∫°n h·ªôi tho·∫°i sau v√† L·ªåC B·ªé R√ÅC.
    Ch·ªâ gi·ªØ l·∫°i v√† T√ìM T·∫ÆT c√°c th√¥ng tin gi√° tr·ªã.
    CHAT LOG: {chat_text}
    OUTPUT: Tr·∫£ v·ªÅ t√≥m t·∫Øt s√∫c t√≠ch (50-100 t·ª´). N·∫øu r√°c, tr·∫£ v·ªÅ "NO_INFO".
    """
    try:
        model = genai.GenerativeModel("gemini-2.0-flash")
        res = model.generate_content(crystallize_prompt)
        return res.text.strip()
    except: return "L·ªói AI Filter."

# ==========================================
# üì± 5. GIAO DI·ªÜN CH√çNH
# ==========================================
with st.sidebar:
    st.caption(f"üë§ {st.session_state.user.email}")
    projects = supabase.table("stories").select("*").eq("user_id", st.session_state.user.id).execute()
    proj_map = {p['title']: p for p in projects.data}
    
    st.divider()
    selected_proj_name = st.selectbox("üìÇ Ch·ªçn D·ª± √Ån", ["+ T·∫°o D·ª± √Ån M·ªõi"] + list(proj_map.keys()))
    
    if selected_proj_name == "+ T·∫°o D·ª± √Ån M·ªõi":
        with st.form("new_proj"):
            title = st.text_input("T√™n D·ª± √Ån")
            cat = st.selectbox("Lo·∫°i", ["Writer", "Coder", "Content Creator"])
            if st.form_submit_button("T·∫°o"):
                supabase.table("stories").insert({"title": title, "category": cat, "user_id": st.session_state.user.id}).execute()
                st.rerun()
        st.stop()
    
    current_proj = proj_map[selected_proj_name]
    proj_id = current_proj['id']
    proj_type = current_proj.get('category', 'Writer')
    
    # Load Persona
    persona = PERSONAS.get(proj_type, PERSONAS['Writer'])
    st.info(f"{persona['icon']} Mode: **{proj_type}**")
    
    if st.button("üö™ ƒêƒÉng xu·∫•t (Sidebar)"):
        cookie_manager.delete("supabase_access_token")
        for k in list(st.session_state.keys()): del st.session_state[k]
        st.rerun()

st.title(f"{persona['icon']} {selected_proj_name}")

tab1, tab2, tab3 = st.tabs(["‚úçÔ∏è Workstation", "üí¨ Smart Chat & Memory", "üìö Project Bible"])

# === TAB 1: WORKSTATION (FULL TITLE & META) ===
with tab1:
    # 1. LOAD DATA
    files = supabase.table("chapters").select("chapter_number, title").eq("story_id", proj_id).order("chapter_number").execute()
    
    f_opts = {}
    for f in files.data:
        display_name = f"File {f['chapter_number']}"
        if f['title']: display_name += f": {f['title']}"
        f_opts[display_name] = f['chapter_number']

    sel_file = st.selectbox("üìÇ Ch·ªçn File:", ["-- New --"] + list(f_opts.keys()))
    chap_num = f_opts[sel_file] if sel_file != "-- New --" else len(files.data) + 1
    
    db_content, db_review, db_title = "", "", ""
    if sel_file != "-- New --":
        try:
            res = supabase.table("chapters").select("content, review_content, title").eq("story_id", proj_id).eq("chapter_number", chap_num).execute()
            if res.data: 
                db_content = res.data[0].get('content', '')
                db_review = res.data[0].get('review_content', '')
                db_title = res.data[0].get('title', '')
        except: pass

    if 'current_chap_view' not in st.session_state or st.session_state['current_chap_view'] != chap_num:
        st.session_state['review_res'] = db_review
        st.session_state['current_chap_view'] = chap_num

    st.divider()

    # 2. UI EDIT
    col_edit, col_tool = st.columns([2, 1])
    with col_edit:
        chap_title = st.text_input("üîñ T√™n File", value=db_title, placeholder="VD: S·ª± kh·ªüi ƒë·∫ßu...")
        input_text = st.text_area("N·ªôi dung", value=db_content, height=600)
        
        if st.button("üíæ L∆∞u N·ªôi Dung & T√™n"):
            supabase.table("chapters").upsert({
                "story_id": proj_id, "chapter_number": chap_num, 
                "title": chap_title, "content": input_text
            }, on_conflict="story_id, chapter_number").execute()
            st.toast("ƒê√£ l∆∞u!", icon="‚úÖ")
            time.sleep(0.5)
            st.rerun()

    with col_tool:
        st.write("### ü§ñ Tr·ª£ l√Ω AI")
        # REVIEW
        if st.button("üöÄ Review M·ªõi", type="primary"):
            if not input_text: st.warning("Tr·ªëng!")
            else:
                with st.status("ƒêang ƒë·ªçc..."):
                    context = smart_search_hybrid(input_text[:500], proj_id)
                    final_prompt = f"TITLE: {chap_title}\nCONTEXT: {context}\nCONTENT: {input_text}\nTASK: {persona['review_prompt']}"
                    res = generate_content_with_fallback(final_prompt, system_instruction=persona['core_instruction'], stream=False)
                    st.session_state['review_res'] = res.text
                    st.rerun()
        
        if 'review_res' in st.session_state and st.session_state['review_res']:
            with st.expander("üìù K·∫øt qu·∫£", expanded=True):
                st.markdown(st.session_state['review_res'])
                st.divider()
                if st.button("üíæ L∆∞u Review DB"):
                    supabase.table("chapters").update({"review_content": st.session_state['review_res']}).eq("story_id", proj_id).eq("chapter_number", chap_num).execute()
                    st.toast("Saved Review!")

        st.divider()
        # EXTRACT META
        if st.button("üì• Tr√≠ch xu·∫•t Bible"):
            with st.spinner("Ph√¢n t√≠ch..."):
                meta_desc = "M√¥ t·∫£ ng·∫Øn g·ªçn M·ª§C ƒê√çCH, DI·ªÑN BI·∫æN CH√çNH v√† K·∫æT QU·∫¢ c·ªßa File n√†y."
                if proj_type == "Coder": meta_desc = "M√¥ t·∫£ M·ª§C ƒê√çCH, TH√ÄNH PH·∫¶N CH√çNH (H√†m/Class) v√† INPUT/OUTPUT."
                
                extra_req = f"""
                Y√äU C·∫¶U B·∫ÆT BU·ªòC: Th√™m v√†o ƒë·∫ßu JSON m·ªôt m·ª•c t·ªïng h·ª£p:
                - entity_name: "[META] {chap_title if chap_title else f'File {chap_num}'}"
                - type: "Overview"
                - description: "{meta_desc}"
                """
                ext_prompt = f"TITLE: {chap_title}\nCONTENT: {input_text}\nTASK: {persona['extractor_prompt']}\n{extra_req}"
                try:
                    res = generate_content_with_fallback(ext_prompt, system_instruction="JSON Only", stream=False)
                    st.session_state['extract_json'] = res.text
                except: st.error("L·ªói AI.")

        if 'extract_json' in st.session_state:
            with st.expander("Preview", expanded=True):
                try:
                    clean = st.session_state['extract_json'].replace("```json", "").replace("```", "").strip()
                    data = json.loads(clean)
                    st.dataframe(pd.DataFrame(data)[['entity_name', 'type', 'description']], hide_index=True)
                    if st.button("üíæ Save to Bible"):
                        for item in data:
                            vec = get_embedding(f"{item.get('description')} {item.get('quote', '')}")
                            if vec: # Ch·ªâ l∆∞u n·∫øu c√≥ embedding
                                supabase.table("story_bible").insert({
                                    "story_id": proj_id, "entity_name": item['entity_name'],
                                    "description": item['description'], "embedding": vec, "source_chapter": chap_num
                                }).execute()
                        st.success("ƒê√£ l∆∞u!")
                        del st.session_state['extract_json']
                except Exception as e: st.error(f"L·ªói Format: {e}")

# === TAB 2: SMART CHAT (FIX L·ªñI CLEAR SCREEN) ===
with tab2:
    col_left, col_right = st.columns([3, 1])
    
    # --- C·ªòT PH·∫¢I: QU·∫¢N L√ù K√ù ·ª®C ---
    with col_right:
        st.write("### üß† K√Ω ·ª©c")
        use_bible = st.toggle("D√πng Bible Context", value=True)
        
        # [FIX LOGIC CLEAR SCREEN]
        # Thay v√¨ x√≥a DB, ta ƒë·∫∑t m·ªôt m·ªëc th·ªùi gian ƒë·ªÉ ·∫©n tin nh·∫Øn c≈©
        if 'chat_cutoff' not in st.session_state:
            st.session_state['chat_cutoff'] = "1970-01-01" # M·∫∑c ƒë·ªãnh hi·ªán t·∫•t c·∫£

        if st.button("üßπ Clear Screen"):
            # ƒê·∫∑t m·ªëc cutoff l√† gi·ªù hi·ªán t·∫°i -> ·∫®n h·∫øt tin c≈©
            st.session_state['chat_cutoff'] = datetime.now().isoformat()
            st.rerun()
        
        if st.button("üîÑ Hi·ªán l·∫°i to√†n b·ªô l·ªãch s·ª≠"):
             st.session_state['chat_cutoff'] = "1970-01-01"
             st.rerun()

        st.divider()

        with st.expander("üíé K·∫øt tinh Chat"):
            st.caption("L∆∞u √Ω ch√≠nh v√†o Bible.")
            crys_option = st.radio("Ph·∫°m vi:", ["20 tin g·∫ßn nh·∫•t", "To√†n b·ªô phi√™n"])
            memory_topic = st.text_input("Ch·ªß ƒë·ªÅ:", placeholder="VD: Magic System")
            if st.button("‚ú® K·∫øt tinh"):
                limit = 20 if crys_option == "20 tin g·∫ßn nh·∫•t" else 100
                chat_data = supabase.table("chat_history").select("*").eq("story_id", proj_id).order("created_at", desc=True).limit(limit).execute().data
                chat_data.reverse()
                if chat_data:
                    with st.spinner("ƒêang t√≥m t·∫Øt..."):
                        summary = crystallize_session(chat_data, persona['role'])
                        if summary != "NO_INFO":
                            st.session_state['crys_summary'] = summary
                            st.session_state['crys_topic'] = memory_topic if memory_topic else f"Chat {datetime.now().strftime('%d/%m')}"
                        else: st.warning("Kh√¥ng c√≥ th√¥ng tin gi√° tr·ªã.")

    if 'crys_summary' in st.session_state:
        with col_right:
            final_sum = st.text_area("Hi·ªáu ch·ªânh:", value=st.session_state['crys_summary'])
            if st.button("üíæ L∆∞u K√Ω ·ª©c"):
                vec = get_embedding(final_sum)
                if vec:
                    supabase.table("story_bible").insert({
                        "story_id": proj_id, "entity_name": f"[CHAT] {st.session_state['crys_topic']}",
                        "description": final_sum, "embedding": vec, "source_chapter": 0
                    }).execute()
                    st.toast("ƒê√£ l∆∞u!")
                    del st.session_state['crys_summary']
                    st.rerun()

    # --- C·ªòT TR√ÅI: CHAT UI ---
    with col_left:
        # 1. Load History t·ª´ DB
        try:
            # L·∫•y 50 tin g·∫ßn nh·∫•t
            msgs = supabase.table("chat_history").select("*").eq("story_id", proj_id).order("created_at", desc=False).limit(50).execute().data
            
            # [QUAN TR·ªåNG] L·ªçc tin nh·∫Øn d·ª±a tr√™n m·ªëc 'chat_cutoff'
            visible_msgs = [m for m in msgs if m['created_at'] > st.session_state['chat_cutoff']]
            
            for m in visible_msgs:
                with st.chat_message(m['role']): st.markdown(m['content'])
        except: pass

        # 2. X·ª≠ l√Ω khi User Chat
        if prompt := st.chat_input("H·ªèi V..."):
            with st.chat_message("user"): st.markdown(prompt)
            
            with st.spinner("Thinking..."):
                # Context Building
                route = ai_router_pro(prompt)
                target_chap = route.get('target_chapter')
                ctx = ""
                note = []
                
                if target_chap:
                    c = supabase.table("chapters").select("content").eq("story_id", proj_id).eq("chapter_number", target_chap).execute()
                    if c.data: 
                        ctx += f"\n--- CHAP {target_chap} ---\n{c.data[0]['content']}\n"
                        note.append(f"Read Chap {target_chap}")
                
                if use_bible:
                    bible_res = smart_search_hybrid(prompt, proj_id)
                    if bible_res: 
                        ctx += f"\n--- BIBLE ---\n{bible_res}\n"
                        note.append("Bible")

                # L·∫•y context t·ª´ tin nh·∫Øn hi·ªÉn th·ªã g·∫ßn ƒë√¢y (Visible messages only)
                # ƒê·ªÉ AI kh√¥ng b·ªã l·∫´n l·ªôn v·ªõi nh·ªØng g√¨ √¥ng ƒë√£ Clear
                recent_msgs = [m for m in msgs if m['created_at'] > st.session_state['chat_cutoff']]
                recent = "\n".join([f"{m['role']}: {m['content']}" for m in recent_msgs[-10:]])
                
                ctx += f"\n--- RECENT ---\n{recent}"
                final = f"CONTEXT:\n{ctx}\n\nUSER: {prompt}"

                try:
                    res_stream = generate_content_with_fallback(final, system_instruction=persona['core_instruction'])
                    
                    with st.chat_message("assistant"):
                        def stream_parser(stream):
                            for chunk in stream:
                                if chunk.text: yield chunk.text
                        
                        full_res = st.write_stream(stream_parser(res_stream))
                        st.caption(f"‚ÑπÔ∏è {', '.join(note) if note else 'Chat Only'}")
                    
                    # L∆∞u v√†o DB
                    if full_res:
                        supabase.table("chat_history").insert([
                            {"story_id": proj_id, "role": "user", "content": str(prompt)},
                            {"story_id": proj_id, "role": "model", "content": str(full_res)}
                        ]).execute()
                        
                        st.rerun()

                except Exception as e: st.error(f"L·ªói Chat: {e}")

# === TAB 3: BIBLE (FIX L·ªñI MERGE) ===
with tab3:
    st.subheader("üìö Project Bible")
    if st.button("üîÑ Refresh"): st.rerun()
    
    bible = supabase.table("story_bible").select("*").eq("story_id", proj_id).order("created_at", desc=True).execute().data
    if bible:
        opts = {f"{b['entity_name']}": b for b in bible}
        selections = st.multiselect("Ch·ªçn m·ª•c G·ªôp/X√≥a:", opts.keys())
        
        c1, c2 = st.columns(2)
        if c1.button("üî• X√≥a"):
            ids = [opts[k]['id'] for k in selections]
            supabase.table("story_bible").delete().in_("id", ids).execute()
            st.success("ƒê√£ x√≥a!")
            time.sleep(0.5)
            st.rerun()
            
        if c2.button("üß¨ G·ªôp (AI Merge)"):
            if len(selections) < 2: st.warning("Ch·ªçn >= 2 m·ª•c!")
            else:
                items = [opts[k] for k in selections]
                txt = "\n".join([f"- {i['description']}" for i in items])
                prompt_merge = f"G·ªôp c√°c m·ª•c sau th√†nh 1 n·ªôi dung duy nh·∫•t:\n{txt}"
                
                try:
                    res = generate_content_with_fallback(prompt_merge, system_instruction="Merge Expert", stream=False)
                    merged_text = res.text
                    
                    # === FIX: Ki·ªÉm tra k·∫øt qu·∫£ tr∆∞·ªõc khi embed ===
                    if not merged_text or not merged_text.strip():
                        st.error("AI tr·∫£ v·ªÅ r·ªóng, kh√¥ng th·ªÉ g·ªôp.")
                    else:
                        vec = get_embedding(merged_text)
                        if vec:
                            supabase.table("story_bible").insert({
                                "story_id": proj_id, "entity_name": items[0]['entity_name'],
                                "description": merged_text, "embedding": vec, "source_chapter": items[0]['source_chapter']
                            }).execute()
                            ids = [i['id'] for i in items]
                            supabase.table("story_bible").delete().in_("id", ids).execute()
                            st.success("G·ªôp xong!")
                            time.sleep(0.5)
                            st.rerun()
                        else: st.error("L·ªói Embedding.")
                except Exception as e: st.error(f"L·ªói: {e}")
        
        st.dataframe(pd.DataFrame(bible)[['entity_name', 'description']], use_container_width=True)
    else: st.info("Bible tr·ªëng.")



