import streamlit as st
import google.generativeai as genai
from supabase import create_client, Client
import json
import re
import pandas as pd
import time
from datetime import datetime
import extra_streamlit_components as stx
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from google.api_core.exceptions import ResourceExhausted, DeadlineExceeded, ServiceUnavailable
from persona import PERSONAS

# ==========================================
# üé® 1. C·∫§U H√åNH & CSS
# ==========================================
st.set_page_config(page_title="V-Universe Hub", page_icon="üåå", layout="wide")

st.markdown("""
<style>
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] { height: 50px; background-color: #f0f2f6; border-radius: 5px; }
    .stTabs [aria-selected="true"] { background-color: #ff4b4b; color: white; }
    div[data-testid="stExpander"] { background-color: #f8f9fa; border-radius: 10px; border: 1px solid #ddd; }
    .stToast { background-color: #333; color: white; }
</style>
""", unsafe_allow_html=True)

# TH√ÅO X√çCH AN TO√ÄN
SAFE_CONFIG = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}
MODEL_PRIORITY = ["gemini-3-flash-preview", "gemini-2.5-flash", "gemini-2.0-flash"]

# --- 2. KH·ªûI T·∫†O K·∫æT N·ªêI (AN TO√ÄN) ---
def init_services():
    try:
        SUPABASE_URL = st.secrets["supabase"]["SUPABASE_URL"]
        SUPABASE_KEY = st.secrets["supabase"]["SUPABASE_KEY"]
        GEMINI_KEY = st.secrets["gemini"]["API_KEY"]
        
        client = create_client(SUPABASE_URL, SUPABASE_KEY)
        genai.configure(api_key=GEMINI_KEY)
        return client
    except Exception as e:
        return None

supabase = init_services()

if not supabase:
    st.error("‚ùå L·ªói k·∫øt n·ªëi! Ki·ªÉm tra l·∫°i file secrets.toml")
    st.stop()

# --- 3. COOKIE MANAGER & LOGIN ---
cookie_manager = stx.CookieManager()

def check_login_status():
    if 'user' not in st.session_state:
        if 'cookie_check_done' not in st.session_state:
            with st.spinner("‚è≥ ƒêang l·ª•c l·ªçi k√Ω ·ª©c (Ch·ªù 3s)..."):
                time.sleep(1) 
                access_token = cookie_manager.get("supabase_access_token")
                refresh_token = cookie_manager.get("supabase_refresh_token")
                
                if access_token and refresh_token:
                    try:
                        session = supabase.auth.set_session(access_token, refresh_token)
                        if session:
                            st.session_state.user = session.user
                            st.toast("üëã M·ª´ng √¥ng gi√°o tr·ªü l·∫°i!", icon="üç™")
                            st.rerun() 
                    except: pass
                st.session_state['cookie_check_done'] = True
                st.rerun()

    if 'user' not in st.session_state:
        st.title("üîê ƒêƒÉng nh·∫≠p V-Brainer")
        col_main, _ = st.columns([1, 1])
        with col_main:
            email = st.text_input("Email")
            password = st.text_input("M·∫≠t kh·∫©u", type="password")
            
            c1, c2 = st.columns(2)
            if c1.button("ƒêƒÉng Nh·∫≠p", type="primary", use_container_width=True):
                try:
                    res = supabase.auth.sign_in_with_password({"email": email, "password": password})
                    st.session_state.user = res.user
                    cookie_manager.set("supabase_access_token", res.session.access_token, key="set_access")
                    cookie_manager.set("supabase_refresh_token", res.session.refresh_token, key="set_refresh")
                    st.success("ƒêƒÉng nh·∫≠p th√†nh c√¥ng!")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"L·ªói: {e}")
            if c2.button("ƒêƒÉng K√Ω", use_container_width=True):
                try:
                    res = supabase.auth.sign_up({"email": email, "password": password})
                    st.session_state.user = res.user
                    if res.session:
                        cookie_manager.set("supabase_access_token", res.session.access_token, key="set_acc_up")
                        cookie_manager.set("supabase_refresh_token", res.session.refresh_token, key="set_ref_up")
                    st.success("T·∫°o user th√†nh c√¥ng!")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"L·ªói: {e}")
        st.stop() 

check_login_status()

# --- SIDEBAR ---
with st.sidebar:
    st.info(f"üë§ {st.session_state.user.email}")
    if st.button("üö™ ƒêƒÉng xu·∫•t", use_container_width=True):
        supabase.auth.sign_out()
        cookie_manager.delete("supabase_access_token")
        cookie_manager.delete("supabase_refresh_token")
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

# ==========================================
# üß† 4. CORE AI LOGIC (N√ÇNG C·∫§P AGENTIC)
# ==========================================

# --- A. HELPER FUNCTIONS ---

def clean_json_text(text):
    """L√†m s·∫°ch markdown (```json ... ```) tr∆∞·ªõc khi parse"""
    if not text: return "{}"
    text = text.replace("```json", "").replace("```", "").strip()
    start = text.find("{")
    end = text.rfind("}") + 1
    if start != -1 and end != 0:
        return text[start:end]
    return text
    
def get_embedding(text):
    if not text or not isinstance(text, str) or not text.strip():
        return None 
    try:
        return genai.embed_content(model="models/text-embedding-004", content=text, task_type="retrieval_document")['embedding']
    except: return None

# --- S·ª¨A L·∫†I H√ÄM N√ÄY ·ªû ƒê·∫¶U FILE ---
def generate_content_with_fallback(prompt, system_instruction, stream=True, temperature=1.0):
    for model_name in MODEL_PRIORITY:
        try:
            model = genai.GenerativeModel(model_name, system_instruction=system_instruction)
            response = model.generate_content(
                prompt, safety_settings=SAFE_CONFIG, stream=stream, 
                generation_config=genai.types.GenerationConfig(temperature=temperature), # <--- Th√™m d√≤ng n√†y
                request_options={'timeout': 60}
            )
            return response
        except Exception as e: continue
    raise Exception("All models failed")

def crystallize_session(chat_history, persona_role):
    chat_text = "\n".join([f"{m['role']}: {m['content']}" for m in chat_history])
    crystallize_prompt = f"""
    B·∫°n l√† Th∆∞ K√Ω Ghi Ch√©p ({persona_role}).
    Nhi·ªám v·ª•: ƒê·ªçc ƒëo·∫°n h·ªôi tho·∫°i sau v√† L·ªåC B·ªé R√ÅC.
    Ch·ªâ gi·ªØ l·∫°i v√† T√ìM T·∫ÆT c√°c th√¥ng tin gi√° tr·ªã (Fact, Idea, Decision).
    CHAT LOG: {chat_text}
    OUTPUT: Tr·∫£ v·ªÅ t√≥m t·∫Øt s√∫c t√≠ch (50-100 t·ª´). N·∫øu r√°c, tr·∫£ v·ªÅ "NO_INFO".
    """
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        res = model.generate_content(crystallize_prompt)
        return res.text.strip()
    except: return "L·ªói AI Filter."

# --- B. SEARCH LOGIC (HYBRID) ---
def smart_search_hybrid_raw(query_text, project_id, top_k=10):
    """H√†m g·ªëc tr·∫£ v·ªÅ List Object (C√≥ ID, d√πng cho Rule Check)"""
    try:
        query_vec = get_embedding(query_text)
        if not query_vec: return []
        
        response = supabase.rpc("hybrid_search", {
            "query_text": query_text, 
            "query_embedding": query_vec,
            "match_threshold": 0.3, 
            "match_count": top_k, 
            "story_id_input": project_id
        }).execute()
        return response.data if response.data else []
    except: return []

def smart_search_hybrid(query_text, project_id, top_k=10):
    """Wrapper tr·∫£ v·ªÅ String Context"""
    raw_data = smart_search_hybrid_raw(query_text, project_id, top_k)
    results = []
    if raw_data:
        for item in raw_data:
            results.append(f"- [{item['entity_name']}]: {item['description']}")
    return "\n".join(results) if results else ""

# --- C. [AGENT MODULE] ROUTER & LOADER (NEW) ---
def ai_router_pro_v2(user_prompt, chat_history_text):
    """Router V2: Ph√¢n t√≠ch Intent v√† Target Files"""
    router_prompt = f"""
    ƒê√≥ng vai Project Coordinator. Ph√¢n t√≠ch User Input v√† L·ªãch s·ª≠ Chat.
    
    L·ªäCH S·ª¨ CHAT:
    {chat_history_text}
    
    USER INPUT: "{user_prompt}"
    
    PH√ÇN LO·∫†I INTENT:
    1. "read_full_content": Khi user mu·ªën "S·ª≠a", "Refactor", "Review", "So s√°nh", "Vi·∫øt ti·∫øp", "Ki·ªÉm tra code/vƒÉn" -> C·∫ßn ƒë·ªçc NGUY√äN VƒÇN FILE.
    2. "search_bible": Khi user h·ªèi th√¥ng tin chung, quy ƒë·ªãnh, c·ªët truy·ªán t√≥m t·∫Øt, tra c·ª©u kh√°i ni·ªám -> Tra c·ª©u Bible (Vector).
    3. "chat_casual": Ch√†o h·ªèi, ch√©m gi√≥ kh√¥ng c·∫ßn context.
    
    OUTPUT JSON ONLY:
    {{
        "intent": "read_full_content" | "search_bible" | "chat_casual",
        "target_files": ["t√™n file 1", "t√™n file 2", "t√™n ch∆∞∆°ng..."], 
        "reason": "L√Ω do ng·∫Øn g·ªçn",
        "rewritten_query": "Vi·∫øt l·∫°i c√¢u h·ªèi cho r√µ nghƒ©a (thay th·∫ø 'n√≥', 'file n√†y' b·∫±ng t√™n th·ª±c th·ªÉ)"
    }}
    """
    try:
        model = genai.GenerativeModel("gemini-2.0-flash")
        res = model.generate_content(router_prompt, generation_config={"response_mime_type": "application/json"})
        return json.loads(clean_json_text(res.text))
    except Exception: 
        return {"intent": "chat_casual", "target_files": [], "rewritten_query": user_prompt}

def load_full_content(file_names, project_id):
    """Load to√†n vƒÉn n·ªôi dung c·ªßa nhi·ªÅu file/ch∆∞∆°ng"""
    if not file_names: return "", []
    
    full_text = ""
    loaded_sources = []
    
    for name in file_names:
        # 1. T√¨m trong Chapters (Full)
        res = supabase.table("chapters").select("chapter_number, title, content").eq("story_id", project_id).ilike("title", f"%{name}%").execute()
        
        if res.data:
            item = res.data[0]
            full_text += f"\n\n=== üìÑ SOURCE FILE/CHAP: {item['title']} ===\n{item['content']}\n"
            loaded_sources.append(f"üìÑ {item['title']}")
        else:
            # 2. T√¨m trong Bible (Summary Fallback)
            res_bible = supabase.table("story_bible").select("entity_name, description").eq("story_id", project_id).ilike("entity_name", f"%{name}%").execute()
            if res_bible.data:
                item = res_bible.data[0]
                full_text += f"\n\n=== ‚ö†Ô∏è BIBLE SUMMARY (Ch·ªâ l√† t√≥m t·∫Øt): {item['entity_name']} ===\n{item['description']}\n"
                loaded_sources.append(f"üóÇÔ∏è {item['entity_name']} (Summary)")

    return full_text, loaded_sources

# --- D. [AGENT MODULE] RULE MINING (NEW) ---
def get_mandatory_rules(project_id):
    """L·∫•y t·∫•t c·∫£ c√°c lu·∫≠t (RULE) b·∫Øt bu·ªôc"""
    try:
        # T√¨m c√°c entity b·∫Øt ƒë·∫ßu b·∫±ng [RULE]
        res = supabase.table("story_bible").select("description").eq("story_id", project_id).ilike("entity_name", "%[RULE]%").execute()
        if res.data:
            rules_text = "\n".join([f"- {r['description']}" for r in res.data])
            return f"\nüî• --- QUY T·∫ÆC B·∫ÆT BU·ªòC (MANDATORY RULES) ---\n{rules_text}\n"
        return ""
    except: return ""

def extract_rule_raw(user_prompt, ai_response):
    """Tr√≠ch xu·∫•t lu·∫≠t th√¥ t·ª´ h·ªôi tho·∫°i (ƒê√£ n√¢ng c·∫•p ƒë·ªô nh·∫°y)"""
    prompt = f"""
    B·∫°n l√† "Rule Extractor". Nhi·ªám v·ª•: Ph√°t hi·ªán User Preference qua h·ªôi tho·∫°i.
    
    H·ªòI THO·∫†I:
    - User: "{user_prompt}"
    - AI: (Ph·∫£n h·ªìi tr∆∞·ªõc ƒë√≥...)
    
    H√ÉY PH√ÇN T√çCH XEM USER C√ì ƒêANG:
    1. Ph√†n n√†n v·ªÅ ƒë·ªô d√†i/phong c√°ch (VD: "d√†i qu√°", "n√≥i √≠t th√¥i", "ƒë·ª´ng gi·∫£i th√≠ch").
    2. ƒê∆∞a ra format b·∫Øt bu·ªôc (VD: "ch·ªâ code th√¥i", "d√πng JSON").
    3. S·ª≠a l∆∞ng AI (VD: "sai r·ªìi", "ph·∫£i l√†m th·∫ø n√†y").
    
    N·∫æU C√ì, h√£y tr√≠ch xu·∫•t th√†nh 1 QUY T·∫ÆC NG·∫ÆN G·ªåN (M·ªánh l·ªánh th·ª©c).
    V√≠ d·ª•: 
    - Input: "N√≥i nhi·ªÅu qu√°, code th√¥i" -> Rule: "Khi user h·ªèi code -> Ch·ªâ ƒë∆∞a Code Block, kh√¥ng gi·∫£i th√≠ch d√†i d√≤ng."
    
    N·∫æU KH√îNG (ch·ªâ l√† chat ti·∫øp, h·ªèi th√™m, c·∫£m ∆°n), tr·∫£ v·ªÅ "NO_RULE".
    
    Output Text Only.
    """
    try:
        model = genai.GenerativeModel("gemini-2.5-flash")
        res = model.generate_content(prompt)
        text = res.text.strip()
        # L·ªçc th√™m 1 l·ªõp cho ch·∫Øc
        if "NO_RULE" in text or len(text) < 5: 
            return None
        return text
    except: return None

def analyze_rule_conflict(new_rule_content, project_id):
    """Check xung ƒë·ªôt lu·∫≠t v·ªõi DB"""
    similar_rules_str = smart_search_hybrid(new_rule_content, project_id, top_k=3)
    
    if not similar_rules_str:
        return {"status": "NEW", "reason": "Kh√¥ng tr√πng ai c·∫£", "suggested_content": new_rule_content}

    judge_prompt = f"""
    Lu·∫≠t M·ªõi: "{new_rule_content}"
    Lu·∫≠t C≈© trong DB: "{similar_rules_str}"
    
    H√£y so s√°nh m·ªëi quan h·ªá:
    - CONFLICT: M√¢u thu·∫´n tr·ª±c ti·∫øp (VD: C≈© b·∫£o A, M·ªõi b·∫£o kh√¥ng A).
    - MERGE: C√πng ch·ªß ƒë·ªÅ nh∆∞ng M·ªõi chi ti·∫øt h∆°n/b·ªï sung.
    - NEW: Kh√°c ch·ªß ƒë·ªÅ.
    
    OUTPUT JSON:
    {{
        "status": "CONFLICT" | "MERGE" | "NEW",
        "existing_rule_summary": "T√≥m t·∫Øt lu·∫≠t c≈© ng·∫Øn g·ªçn",
        "reason": "L√Ω do",
        "merged_content": "N·ªôi dung g·ªôp ho√†n ch·ªânh (n·∫øu MERGE). N·∫øu CONFLICT/NEW ƒë·ªÉ null."
    }}
    """
    try:
        model = genai.GenerativeModel("gemini-2.0-flash")
        res = model.generate_content(judge_prompt, generation_config={"response_mime_type": "application/json"})
        return json.loads(clean_json_text(res.text))
    except:
        return {"status": "NEW", "reason": "AI Judge Error", "suggested_content": new_rule_content}

# ==========================================
# üì± 5. GIAO DI·ªÜN CH√çNH
# ==========================================
with st.sidebar:
    st.caption(f"üë§ {st.session_state.user.email}")
    projects = supabase.table("stories").select("*").eq("user_id", st.session_state.user.id).execute()
    proj_map = {p['title']: p for p in projects.data}
    
    st.divider()
    selected_proj_name = st.selectbox("üìÇ Ch·ªçn D·ª± √Ån", ["+ T·∫°o D·ª± √Ån M·ªõi"] + list(proj_map.keys()))
    
    if selected_proj_name == "+ T·∫°o D·ª± √Ån M·ªõi":
        with st.form("new_proj"):
            title = st.text_input("T√™n D·ª± √Ån")
            cat = st.selectbox("Lo·∫°i", ["Writer", "Coder", "Content Creator"])
            if st.form_submit_button("T·∫°o"):
                supabase.table("stories").insert({"title": title, "category": cat, "user_id": st.session_state.user.id}).execute()
                st.rerun()
        st.stop()
    
    current_proj = proj_map[selected_proj_name]
    proj_id = current_proj['id']
    proj_type = current_proj.get('category', 'Writer')
    
    # Load Persona
    persona = PERSONAS.get(proj_type, PERSONAS['Writer'])
    st.info(f"{persona['icon']} Mode: **{proj_type}**")
    
    if st.button("üö™ ƒêƒÉng xu·∫•t (Sidebar)"):
        cookie_manager.delete("supabase_access_token")
        for k in list(st.session_state.keys()): del st.session_state[k]
        st.rerun()

st.title(f"{persona['icon']} {selected_proj_name}")

tab1, tab2, tab3 = st.tabs(["‚úçÔ∏è Workstation", "üí¨ Smart Chat With V", "üìö Project Bible"])

# === TAB 1: WORKSTATION (GI·ªÆ NGUY√äN) ===
with tab1:
    files = supabase.table("chapters").select("chapter_number, title").eq("story_id", proj_id).order("chapter_number").execute()
    f_opts = {}
    for f in files.data:
        display_name = f"File {f['chapter_number']}"
        if f['title']: display_name += f": {f['title']}"
        f_opts[display_name] = f['chapter_number']

    sel_file = st.selectbox("üìÇ Ch·ªçn File:", ["-- New --"] + list(f_opts.keys()))
    chap_num = f_opts[sel_file] if sel_file != "-- New --" else len(files.data) + 1
    
    db_content, db_review, db_title = "", "", ""
    if sel_file != "-- New --":
        try:
            res = supabase.table("chapters").select("content, review_content, title").eq("story_id", proj_id).eq("chapter_number", chap_num).execute()
            if res.data: 
                db_content = res.data[0].get('content', '')
                db_review = res.data[0].get('review_content', '')
                db_title = res.data[0].get('title', '')
        except: pass

    if 'current_chap_view' not in st.session_state or st.session_state['current_chap_view'] != chap_num:
        st.session_state['review_res'] = db_review
        st.session_state['current_chap_view'] = chap_num

    st.divider()

    col_edit, col_tool = st.columns([2, 1])
    with col_edit:
        chap_title = st.text_input("üîñ T√™n File", value=db_title, placeholder="VD: S·ª± kh·ªüi ƒë·∫ßu...")
        input_text = st.text_area("N·ªôi dung", value=db_content, height=600)
        
        if st.button("üíæ L∆∞u N·ªôi Dung & T√™n"):
            supabase.table("chapters").upsert({
                "story_id": proj_id, "chapter_number": chap_num, 
                "title": chap_title, "content": input_text
            }, on_conflict="story_id, chapter_number").execute()
            st.toast("ƒê√£ l∆∞u!", icon="‚úÖ")
            time.sleep(0.5)
            st.rerun()

    with col_tool:
        st.write("### ü§ñ Tr·ª£ l√Ω AI")
        if st.button("üöÄ Review M·ªõi", type="primary"):
            if not input_text: st.warning("Tr·ªëng!")
            else:
                with st.status("ƒêang ƒë·ªçc..."):
                    context = smart_search_hybrid(input_text[:500], proj_id)
                    rules = get_mandatory_rules(proj_id) # Ch√®n Rule
                    final_prompt = f"RULES: {rules}\nTITLE: {chap_title}\nCONTEXT: {context}\nCONTENT: {input_text}\nTASK: {persona['review_prompt']}"
                    res = generate_content_with_fallback(final_prompt, system_instruction=persona['core_instruction'], stream=False)
                    st.session_state['review_res'] = res.text
                    st.rerun()
        
        if 'review_res' in st.session_state and st.session_state['review_res']:
            with st.expander("üìù K·∫øt qu·∫£", expanded=True):
                st.markdown(st.session_state['review_res'])
                st.divider()
                if st.button("üíæ L∆∞u Review DB"):
                    supabase.table("chapters").update({"review_content": st.session_state['review_res']}).eq("story_id", proj_id).eq("chapter_number", chap_num).execute()
                    st.toast("Saved Review!")

        st.divider()
        if st.button("üì• Tr√≠ch xu·∫•t Bible"):
            with st.spinner("Ph√¢n t√≠ch..."):
                meta_desc = "M√¥ t·∫£ ng·∫Øn g·ªçn M·ª§C ƒê√çCH, DI·ªÑN BI·∫æN CH√çNH v√† K·∫æT QU·∫¢ c·ªßa File n√†y."
                if proj_type == "Coder": meta_desc = "M√¥ t·∫£ M·ª§C ƒê√çCH, TH√ÄNH PH·∫¶N CH√çNH (H√†m/Class) v√† INPUT/OUTPUT."
                
                extra_req = f"""
                Y√äU C·∫¶U B·∫ÆT BU·ªòC: Th√™m v√†o ƒë·∫ßu JSON m·ªôt m·ª•c t·ªïng h·ª£p:
                - entity_name: "[META] {chap_title if chap_title else f'File {chap_num}'}"
                - type: "Overview"
                - description: "{meta_desc}"
                """
                ext_prompt = f"TITLE: {chap_title}\nCONTENT: {input_text}\nTASK: {persona['extractor_prompt']}\n{extra_req}"
                try:
                    res = generate_content_with_fallback(ext_prompt, system_instruction="JSON Only", stream=False)
                    st.session_state['extract_json'] = res.text
                except: st.error("L·ªói AI.")

        if 'extract_json' in st.session_state:
            with st.expander("Preview", expanded=True):
                try:
                    clean = clean_json_text(st.session_state['extract_json'])
                    data = json.loads(clean)
                    st.dataframe(pd.DataFrame(data)[['entity_name', 'type', 'description']], hide_index=True)
                    if st.button("üíæ Save to Bible"):
                        for item in data:
                            vec = get_embedding(f"{item.get('description')} {item.get('quote', '')}")
                            if vec: 
                                supabase.table("story_bible").insert({
                                    "story_id": proj_id, "entity_name": item['entity_name'],
                                    "description": item['description'], "embedding": vec, "source_chapter": chap_num
                                }).execute()
                        st.success("ƒê√£ l∆∞u!")
                        del st.session_state['extract_json']
                except Exception as e: st.error(f"L·ªói Format: {e}")

# === TAB 2: SMART CHAT (S·ª¨A LOGIC AGENTIC) ===
with tab2:
    col_left, col_right = st.columns([3, 1])
    
    # --- C·ªòT PH·∫¢I: K√ù ·ª®C ---
    with col_right:
        st.write("### üß† K√Ω ·ª©c")
        if 'chat_cutoff' not in st.session_state: st.session_state['chat_cutoff'] = "1970-01-01" 
        
        if st.button("üßπ Clear Screen"):
            st.session_state['chat_cutoff'] = datetime.utcnow().isoformat()
            st.rerun()
            
        if st.button("üîÑ Hi·ªán l·∫°i to√†n b·ªô"):
             st.session_state['chat_cutoff'] = "1970-01-01"
             st.rerun()
        # === TH√äM C√ÅI N√ÄY ===
        strict_mode = st.toggle(
            "üö´ Ch·∫ø ƒë·ªô Nghi√™m t√∫c (Strict)", 
            value=False, 
            help="B·∫≠t l√™n: AI ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu t√¨m ƒë∆∞·ª£c. C·∫•m ch√©m gi√≥. (Temp = 0)"
        )
        st.divider()

        # Crystallize logic (Gi·ªØ nguy√™n)
        with st.expander("üíé K·∫øt tinh Chat"):
            st.caption("L∆∞u √Ω ch√≠nh v√†o Bible.")
            crys_option = st.radio("Ph·∫°m vi:", ["20 tin g·∫ßn nh·∫•t", "To√†n b·ªô phi√™n"])
            memory_topic = st.text_input("Ch·ªß ƒë·ªÅ:", placeholder="VD: Magic System")
            if st.button("‚ú® K·∫øt tinh"):
                limit = 20 if crys_option == "20 tin g·∫ßn nh·∫•t" else 100
                chat_data = supabase.table("chat_history").select("*").eq("story_id", proj_id).order("created_at", desc=True).limit(limit).execute().data
                chat_data.reverse()
                if chat_data:
                    with st.spinner("ƒêang t√≥m t·∫Øt..."):
                        summary = crystallize_session(chat_data, persona['role'])
                        if summary != "NO_INFO":
                            st.session_state['crys_summary'] = summary
                            st.session_state['crys_topic'] = memory_topic if memory_topic else f"Chat {datetime.now().strftime('%d/%m')}"
                        else: st.warning("Kh√¥ng c√≥ th√¥ng tin gi√° tr·ªã.")

    if 'crys_summary' in st.session_state:
        with col_right:
            final_sum = st.text_area("Hi·ªáu ch·ªânh:", value=st.session_state['crys_summary'])
            if st.button("üíæ L∆∞u K√Ω ·ª©c"):
                vec = get_embedding(final_sum)
                if vec:
                    supabase.table("story_bible").insert({
                        "story_id": proj_id, "entity_name": f"[CHAT] {st.session_state['crys_topic']}",
                        "description": final_sum, "embedding": vec, "source_chapter": 0
                    }).execute()
                    st.toast("ƒê√£ l∆∞u!")
                    del st.session_state['crys_summary']
                    st.rerun()

    # --- C·ªòT TR√ÅI: CHAT UI & LOGIC AGENT ---
    with col_left:
        # 1. LOAD HISTORY
        try:
            msgs_data = supabase.table("chat_history").select("*").eq("story_id", proj_id).order("created_at", desc=True).limit(50).execute().data
            msgs = msgs_data[::-1] if msgs_data else []
            visible_msgs = [m for m in msgs if m['created_at'] > st.session_state['chat_cutoff']]
            
            for m in visible_msgs:
                with st.chat_message(m['role']):
                    st.markdown(m['content'])
        except Exception as e: st.error(f"L·ªói load history: {e}")

        # 2. X·ª¨ L√ù CHAT M·ªöI
        if prompt := st.chat_input("H·ªèi V (Agentic Mode)..."):
            with st.chat_message("user"): st.markdown(prompt)
            
            with st.spinner("Thinking..."):
                now_timestamp = datetime.utcnow().isoformat()
                
                # --- A. ROUTING ---
                # L·∫•y l·ªãch s·ª≠ chat ƒë·ªÉ Router hi·ªÉu ng·ªØ c·∫£nh
                recent_history_text = "\n".join([f"{m['role']}: {m['content']}" for m in visible_msgs[-5:]])
                router_out = ai_router_pro_v2(prompt, recent_history_text)
                
                intent = router_out.get('intent', 'chat_casual')
                targets = router_out.get('target_files', [])
                rewritten_query = router_out.get('rewritten_query', prompt)
                
                ctx = ""
                debug_notes = [f"Intent: {intent}"]
                
                # --- B. CONTEXT BUILDER ---
                # B1: Mandatory Rules (Lu√¥n lu√¥n l·∫•y)
                mandatory_rules = get_mandatory_rules(proj_id)
                if mandatory_rules:
                    ctx += f"{mandatory_rules}\n"
                    debug_notes.append("Rules Loaded")
                
                # B2: Content Loading (D·ª±a theo Intent)
                if intent == "read_full_content" and targets:
                    full_text, source_names = load_full_content(targets, proj_id)
                    ctx += f"\n--- TARGET CONTENT ---\n{full_text}\n"
                    debug_notes.append(f"Reading: {', '.join(source_names)}")
                    
                elif intent == "search_bible":
                    bible_res = smart_search_hybrid(rewritten_query, proj_id)
                    ctx += f"\n--- KNOWLEDGE BASE ---\n{bible_res}\n"
                    debug_notes.append("Vector Search")
                
                # B3: Chat History
                ctx += f"\n--- RECENT CHAT ---\n{recent_history_text}"

                # --- C. GENERATION (LOGIC M·ªöI) ---
                final_prompt = f"CONTEXT:\n{ctx}\n\nUSER QUERY: {prompt}"
                
                # 1. C·∫•u h√¨nh Strict Mode
                run_instruction = persona['core_instruction']
                run_temperature = 1.0 # M·∫∑c ƒë·ªãnh s√°ng t·∫°o v·ª´a ph·∫£i

                # Bi·∫øn strict_mode l·∫•y t·ª´ c√°i toggle b√™n c·ªôt ph·∫£i (col_right)
                if strict_mode:
                    run_temperature = 0.0 # L·∫°nh l√πng, ch√≠nh x√°c
                    run_instruction += """
                    \n\n‚ÄºÔ∏è STRICT MODE ACTIVATED:
                    1. CH·ªà tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin trong CONTEXT.
                    2. Tuy·ªát ƒë·ªëi KH√îNG d√πng ki·∫øn th·ª©c b√™n ngo√†i (training data) ƒë·ªÉ b·ªãa ƒë·∫∑t.
                    3. N·∫øu kh√¥ng c√≥ th√¥ng tin, tr·∫£ l·ªùi: "D·ªØ li·ªáu d·ª± √°n kh√¥ng c√≥ th√¥ng tin n√†y."
                    """

                try:
                    # G·ªçi h√†m v·ªõi config m·ªõi
                    res_stream = generate_content_with_fallback(
                        final_prompt, 
                        system_instruction=run_instruction, 
                        stream=True,
                        temperature=run_temperature
                    )
                    
                    with st.chat_message("assistant"):
                        if debug_notes: st.caption(f"üß† {', '.join(debug_notes)}")
                        if strict_mode: st.caption("üîí Strict Mode: ON")
                        
                        full_response_text = ""
                        placeholder = st.empty()
                        
                        for chunk in res_stream:
                            if hasattr(chunk, 'text') and chunk.text:
                                full_response_text += chunk.text
                                placeholder.markdown(full_response_text + "‚ñå")
                        placeholder.markdown(full_response_text)
                    
                    # Save Log & Rule Mining (Ch·ªâ l∆∞u n·∫øu enable_history b·∫≠t)
                    # Bi·∫øn enable_history l·∫•y t·ª´ toggle b√™n c·ªôt ph·∫£i
                    if full_response_text and enable_history:
                        # 1. L∆∞u Chat
                        supabase.table("chat_history").insert([
                            {"story_id": proj_id, "role": "user", "content": prompt, "created_at": now_timestamp},
                            {"story_id": proj_id, "role": "model", "content": full_response_text, "created_at": now_timestamp}
                        ]).execute()
                        
                        # 2. H·ªçc Lu·∫≠t M·ªõi (Agentic)
                        new_rule = extract_rule_raw(prompt, full_response_text)
                        if new_rule:
                            st.session_state['pending_new_rule'] = new_rule
                            st.rerun()
                    
                    elif not enable_history:
                        st.caption("üëª Ch·∫ø ƒë·ªô ·∫©n danh: Kh√¥ng l∆∞u l·ªãch s·ª≠ & Kh√¥ng h·ªçc lu·∫≠t.")

                except Exception as e: st.error(f"L·ªói generate: {e}")
                        
                    

    # --- UI X·ª¨ L√ù RULE M·ªöI (N·ªîI L√äN D∆Ø·ªöI INPUT) ---
    if 'pending_new_rule' in st.session_state:
        rule_content = st.session_state['pending_new_rule']
        with st.expander("üßê V ph√°t hi·ªán m·ªôt Quy T·∫Øc m·ªõi!", expanded=True):
            st.write(f"**N·ªôi dung:** {rule_content}")
            
            # Analyze Conflict
            if 'rule_analysis' not in st.session_state:
                with st.spinner("ƒêang ki·ªÉm tra tr√πng l·∫∑p..."):
                    st.session_state['rule_analysis'] = analyze_rule_conflict(rule_content, proj_id)
            
            analysis = st.session_state['rule_analysis']
            st.info(f"ƒê√°nh gi√° AI: **{analysis['status']}** - {analysis['reason']}")
            
            if analysis['status'] == "CONFLICT":
                st.warning(f"‚ö†Ô∏è Xung ƒë·ªôt v·ªõi: {analysis['existing_rule_summary']}")
            elif analysis['status'] == "MERGE":
                st.info(f"üí° G·ª£i √Ω g·ªôp: {analysis['merged_content']}")
            
            c1, c2, c3 = st.columns(3)
            if c1.button("‚úÖ L∆∞u/G·ªôp Rule n√†y"):
                final_content = analysis.get('merged_content') if analysis['status'] == "MERGE" else rule_content
                vec = get_embedding(final_content)
                supabase.table("story_bible").insert({
                    "story_id": proj_id,
                    "entity_name": f"[RULE] {datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "description": final_content,
                    "embedding": vec, "source_chapter": 0
                }).execute()
                st.toast("ƒê√£ h·ªçc thu·ªôc quy t·∫Øc m·ªõi!")
                del st.session_state['pending_new_rule']
                del st.session_state['rule_analysis']
                st.rerun()
                
            if c2.button("‚úèÔ∏è S·ª≠a r·ªìi L∆∞u"):
                st.session_state['edit_rule_manual'] = rule_content
                
            if c3.button("‚ùå B·ªè qua"):
                del st.session_state['pending_new_rule']
                del st.session_state['rule_analysis']
                st.rerun()

        if 'edit_rule_manual' in st.session_state:
             edited = st.text_input("S·ª≠a l·∫°i rule:", value=st.session_state['edit_rule_manual'])
             if st.button("L∆∞u b·∫£n s·ª≠a"):
                vec = get_embedding(edited)
                supabase.table("story_bible").insert({
                    "story_id": proj_id, "entity_name": f"[RULE] Manual",
                    "description": edited, "embedding": vec, "source_chapter": 0
                }).execute()
                del st.session_state['pending_new_rule']
                del st.session_state['rule_analysis']
                del st.session_state['edit_rule_manual']
                st.rerun()

# === TAB 3: BIBLE (GI·ªÆ NGUY√äN LOGIC) ===
with tab3:
    st.subheader("üìö Project Bible Manager")
    
    col_search, col_ref = st.columns([4, 1])
    with col_search:
        search_kw = st.text_input("üîç T√¨m ki·∫øm trong Bible", placeholder="Nh·∫≠p t·ª´ kh√≥a...")
    with col_ref:
        if st.button("üîÑ Refresh", use_container_width=True): st.rerun()

    bible_query = supabase.table("story_bible").select("*").eq("story_id", proj_id).order("created_at", desc=True).execute()
    bible_data = bible_query.data if bible_query.data else []

    filtered_bible = []
    if search_kw:
        kw = search_kw.lower()
        filtered_bible = [b for b in bible_data if kw in b['entity_name'].lower() or kw in b['description'].lower()]
    else:
        filtered_bible = bible_data

    opts = {f"{b['entity_name']}": b for b in filtered_bible}

    with st.expander("‚ûï Th√™m Bible th·ªß c√¥ng", expanded=False):
        with st.form("add_bible_form"):
            new_name = st.text_input("T√™n m·ª•c (Entity Name)")
            new_desc = st.text_area("M√¥ t·∫£ chi ti·∫øt")
            if st.form_submit_button("L∆∞u m·ªõi"):
                if not new_name or not new_desc:
                    st.error("Vui l√≤ng nh·∫≠p ƒë·ªß th√¥ng tin!")
                else:
                    with st.spinner("ƒêang vector h√≥a..."):
                        vec = get_embedding(f"{new_name}: {new_desc}")
                        if vec:
                            supabase.table("story_bible").insert({
                                "story_id": proj_id,
                                "entity_name": new_name, "description": new_desc,
                                "embedding": vec, "source_chapter": 0
                            }).execute()
                            st.success("ƒê√£ th√™m th√†nh c√¥ng!")
                            time.sleep(1)
                            st.rerun()
                        else: st.error("L·ªói t·∫°o Embedding.")

    st.divider()

    if filtered_bible:
        selections = st.multiselect(
            f"Ch·ªçn m·ª•c ƒë·ªÉ thao t√°c (ƒêang hi·ªÉn th·ªã {len(filtered_bible)} m·ª•c):", 
            list(opts.keys()), key="bible_selector"
        )
        
        col_actions = st.columns([1, 1, 2])
        
        with col_actions[0]:
            if st.button("üî• X√≥a M·ª•c Ch·ªçn", use_container_width=True, disabled=len(selections)==0):
                ids = [opts[k]['id'] for k in selections]
                supabase.table("story_bible").delete().in_("id", ids).execute()
                st.success("ƒê√£ x√≥a!")
                time.sleep(0.5)
                st.rerun()

        with col_actions[1]:
            if st.button("üß¨ G·ªôp (AI Merge)", use_container_width=True, disabled=len(selections)<2):
                items = [opts[k] for k in selections]
                txt = "\n".join([f"- {i['description']}" for i in items])
                prompt_merge = f"G·ªôp c√°c m·ª•c sau th√†nh 1 n·ªôi dung duy nh·∫•t:\n{txt}"
                
                try:
                    with st.spinner("AI ƒëang g·ªôp..."):
                        res = generate_content_with_fallback(prompt_merge, system_instruction="Merge Expert", stream=False)
                        merged_text = res.text
                        
                        if merged_text and merged_text.strip():
                            vec = get_embedding(merged_text)
                            if vec: 
                                supabase.table("story_bible").insert({
                                    "story_id": proj_id, "entity_name": items[0]['entity_name'],
                                    "description": merged_text, "embedding": vec, "source_chapter": items[0]['source_chapter']
                                }).execute()
                                ids = [i['id'] for i in items]
                                supabase.table("story_bible").delete().in_("id", ids).execute()
                                st.success("G·ªôp xong!")
                                time.sleep(0.5)
                                st.rerun()
                            else: st.error("L·ªói Embedding.")
                except Exception as e: st.error(f"L·ªói: {e}")

        if len(selections) == 1:
            st.info("üõ†Ô∏è Ch·∫ø ƒë·ªô ch·ªânh s·ª≠a")
            item_to_edit = opts[selections[0]]
            with st.form("edit_bible_form"):
                edit_name = st.text_input("S·ª≠a T√™n", value=item_to_edit['entity_name'])
                edit_desc = st.text_area("S·ª≠a M√¥ t·∫£", value=item_to_edit['description'], height=150)
                
                if st.form_submit_button("C·∫≠p nh·∫≠t & Re-Vectorize"):
                    with st.spinner("ƒêang c·∫≠p nh·∫≠t..."):
                        vec = get_embedding(f"{edit_name}: {edit_desc}")
                        if vec:
                            supabase.table("story_bible").update({
                                "entity_name": edit_name, "description": edit_desc, "embedding": vec
                            }).eq("id", item_to_edit['id']).execute()
                            st.success("ƒê√£ c·∫≠p nh·∫≠t!")
                            time.sleep(1)
                            st.rerun()
                        else: st.error("L·ªói vector h√≥a.")

        st.divider()
        st.dataframe(
            pd.DataFrame(filtered_bible)[['entity_name', 'description', 'created_at']], 
            use_container_width=True, hide_index=True
        )
    else:
        st.info("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ph√π h·ª£p.")
    
    st.divider()
    with st.expander("üíÄ Danger Zone"):
        if st.button("üí£ X√≥a s·∫°ch Bible & Reset", type="primary", use_container_width=True):
            try:
                supabase.table("story_bible").delete().eq("story_id", proj_id).execute()
                st.success("ƒê√£ d·ªçn s·∫°ch s·∫Ω!")
                time.sleep(1)
                st.rerun()
            except Exception as e: st.error(f"L·ªói: {e}")



