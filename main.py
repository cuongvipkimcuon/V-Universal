import streamlit as st
import google.generativeai as genai
from supabase import create_client, Client
import json
import re
import pandas as pd
import time
from datetime import datetime
import extra_streamlit_components as stx
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from google.api_core.exceptions import ResourceExhausted, DeadlineExceeded, ServiceUnavailable
from persona import PERSONAS

# ==========================================
# ğŸ¨ 1. Cáº¤U HÃŒNH & CSS
# ==========================================
st.set_page_config(page_title="V-Universe Hub", page_icon="ğŸŒŒ", layout="wide")

st.markdown("""
<style>
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] { height: 50px; background-color: #f0f2f6; border-radius: 5px; }
    .stTabs [aria-selected="true"] { background-color: #ff4b4b; color: white; }
    div[data-testid="stExpander"] { background-color: #f8f9fa; border-radius: 10px; border: 1px solid #ddd; }
</style>
""", unsafe_allow_html=True)

# THÃO XÃCH AN TOÃ€N
SAFE_CONFIG = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}
MODEL_PRIORITY = ["gemini-3-flash-preview", "gemini-2.5-flash", "gemini-2.0-flash"]

# --- 2. KHá»I Táº O Káº¾T Ná»I (AN TOÃ€N) ---
def init_services():
    try:
        SUPABASE_URL = st.secrets["supabase"]["SUPABASE_URL"]
        SUPABASE_KEY = st.secrets["supabase"]["SUPABASE_KEY"]
        GEMINI_KEY = st.secrets["gemini"]["API_KEY"]
        
        client = create_client(SUPABASE_URL, SUPABASE_KEY)
        genai.configure(api_key=GEMINI_KEY)
        return client
    except Exception as e:
        return None

supabase = init_services()

if not supabase:
    st.error("âŒ Lá»—i káº¿t ná»‘i! Kiá»ƒm tra láº¡i file secrets.toml")
    st.stop()

# --- 3. COOKIE MANAGER & LOGIN ---
cookie_manager = stx.CookieManager()

def check_login_status():
    if 'user' not in st.session_state:
        if 'cookie_check_done' not in st.session_state:
            with st.spinner("â³ Äang lá»¥c lá»i kÃ½ á»©c (Chá» 3s)..."):
                time.sleep(1) 
                access_token = cookie_manager.get("supabase_access_token")
                refresh_token = cookie_manager.get("supabase_refresh_token")
                
                if access_token and refresh_token:
                    try:
                        session = supabase.auth.set_session(access_token, refresh_token)
                        if session:
                            st.session_state.user = session.user
                            st.toast("ğŸ‘‹ Má»«ng Ã´ng giÃ¡o trá»Ÿ láº¡i!", icon="ğŸª")
                            st.rerun() 
                    except: pass
                st.session_state['cookie_check_done'] = True
                st.rerun()

    if 'user' not in st.session_state:
        st.title("ğŸ” ÄÄƒng nháº­p V-Brainer")
        col_main, _ = st.columns([1, 1])
        with col_main:
            email = st.text_input("Email")
            password = st.text_input("Máº­t kháº©u", type="password")
            
            c1, c2 = st.columns(2)
            if c1.button("ÄÄƒng Nháº­p", type="primary", use_container_width=True):
                try:
                    res = supabase.auth.sign_in_with_password({"email": email, "password": password})
                    st.session_state.user = res.user
                    cookie_manager.set("supabase_access_token", res.session.access_token, key="set_access")
                    cookie_manager.set("supabase_refresh_token", res.session.refresh_token, key="set_refresh")
                    st.success("ÄÄƒng nháº­p thÃ nh cÃ´ng!")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"Lá»—i: {e}")
            if c2.button("ÄÄƒng KÃ½", use_container_width=True):
                try:
                    res = supabase.auth.sign_up({"email": email, "password": password})
                    st.session_state.user = res.user
                    if res.session:
                        cookie_manager.set("supabase_access_token", res.session.access_token, key="set_acc_up")
                        cookie_manager.set("supabase_refresh_token", res.session.refresh_token, key="set_ref_up")
                    st.success("Táº¡o user thÃ nh cÃ´ng!")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"Lá»—i: {e}")
        st.stop() 

check_login_status()

# --- SIDEBAR ---
with st.sidebar:
    st.info(f"ğŸ‘¤ {st.session_state.user.email}")
    if st.button("ğŸšª ÄÄƒng xuáº¥t", use_container_width=True):
        supabase.auth.sign_out()
        cookie_manager.delete("supabase_access_token")
        cookie_manager.delete("supabase_refresh_token")
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

# ==========================================
# ğŸ§  4. CORE AI LOGIC (NÃ‚NG Cáº¤P AGENTIC)
# ==========================================

# --- A. HELPER FUNCTIONS ---

def clean_json_text(text):
    """LÃ m sáº¡ch markdown (```json ... ```) trÆ°á»›c khi parse"""
    if not text: return "{}"
    # XÃ³a markdown code block
    text = text.replace("```json", "").replace("```", "").strip()
    # XÃ³a cÃ¡c kÃ½ tá»± láº¡ Ä‘áº§u/cuá»‘i náº¿u cÃ³
    start = text.find("{")
    end = text.rfind("}") + 1
    if start != -1 and end != 0:
        return text[start:end]
    return text
    
def get_embedding(text):
    if not text or not isinstance(text, str) or not text.strip():
        return None 
    try:
        return genai.embed_content(model="models/text-embedding-004", content=text, task_type="retrieval_document")['embedding']
    except: return None

def generate_content_with_fallback(prompt, system_instruction, stream=True):
    for model_name in MODEL_PRIORITY:
        try:
            model = genai.GenerativeModel(model_name, system_instruction=system_instruction)
            response = model.generate_content(
                prompt, safety_settings=SAFE_CONFIG, stream=stream, request_options={'timeout': 60}
            )
            return response
        except Exception as e: continue
    raise Exception("All models failed")

def crystallize_session(chat_history, persona_role):
    chat_text = "\n".join([f"{m['role']}: {m['content']}" for m in chat_history])
    crystallize_prompt = f"""
    Báº¡n lÃ  ThÆ° KÃ½ Ghi ChÃ©p ({persona_role}).
    Nhiá»‡m vá»¥: Äá»c Ä‘oáº¡n há»™i thoáº¡i sau vÃ  Lá»ŒC Bá» RÃC.
    Chá»‰ giá»¯ láº¡i vÃ  TÃ“M Táº®T cÃ¡c thÃ´ng tin giÃ¡ trá»‹.
    CHAT LOG: {chat_text}
    OUTPUT: Tráº£ vá» tÃ³m táº¯t sÃºc tÃ­ch (50-100 tá»«). Náº¿u rÃ¡c, tráº£ vá» "NO_INFO".
    """
    try:
        model = genai.GenerativeModel("gemini-2.5-flash")
        res = model.generate_content(crystallize_prompt)
        return res.text.strip()
    except: return "Lá»—i AI Filter."

# --- B. SEARCH LOGIC (RAW & WRAPPER) ---
def smart_search_hybrid_raw(query_text, project_id, top_k=15):
    """HÃ m gá»‘c tráº£ vá» List Object (CÃ³ ID, dÃ¹ng cho Rule Check)"""
    try:
        query_vec = get_embedding(query_text)
        if not query_vec: return []
        
        response = supabase.rpc("hybrid_search", {
            "query_text": query_text, 
            "query_embedding": query_vec,
            "match_threshold": 0.3, # Threshold tháº¥p Ä‘á»ƒ vÃ©t cáº¡n
            "match_count": top_k, 
            "story_id_input": project_id
        }).execute()
        return response.data if response.data else []
    except: return []

def smart_search_hybrid(query_text, project_id, top_k=15):
    """HÃ m wrapper tráº£ vá» String (DÃ¹ng cho Context Prompt)"""
    raw_data = smart_search_hybrid_raw(query_text, project_id, top_k)
    results = []
    if raw_data:
        for item in raw_data:
            results.append(f"- [{item['entity_name']}]: {item['description']}")
    return "\n".join(results) if results else ""

# --- C. [MODULE 1] ROUTER V2 & LOADER ---
def ai_router_pro_v2(user_prompt, chat_history_text):
    """Router V2: PhÃ¢n tÃ­ch Intent vÃ  Viáº¿t láº¡i cÃ¢u há»i (ÄÃ£ Fix lá»—i JSON)"""
    router_prompt = f"""
    ÄÃ³ng vai Project Coordinator. PhÃ¢n tÃ­ch User Input vÃ  Lá»‹ch sá»­ Chat.
    
    Lá»ŠCH Sá»¬ CHAT:
    {chat_history_text}
    
    USER INPUT: "{user_prompt}"
    
    PHÃ‚N LOáº I INTENT:
    1. "read_full_content": Khi user muá»‘n "Sá»­a", "Refactor", "Review", "So sÃ¡nh", "Viáº¿t tiáº¿p", "Kiá»ƒm tra", "Check" -> Cáº§n Ä‘á»c NGUYÃŠN VÄ‚N FILE.
    2. "search_bible": Khi user há»i thÃ´ng tin chung, quy Ä‘á»‹nh, cá»‘t truyá»‡n tÃ³m táº¯t -> Tra cá»©u Bible.
    3. "chat_casual": ChÃ o há»i, chÃ©m giÃ³.
    
    OUTPUT JSON ONLY:
    {{
        "intent": "read_full_content" | "search_bible" | "chat_casual",
        "target_files": ["tÃªn file 1", "tÃªn file 2", "tÃªn chÆ°Æ¡ng..."], 
        "reason": "LÃ½ do ngáº¯n gá»n",
        "rewritten_query": "Viáº¿t láº¡i cÃ¢u há»i cho rÃµ nghÄ©a (thay tháº¿ 'nÃ³' báº±ng tÃªn thá»±c thá»ƒ)"
    }}
    """
    try:
        model = genai.GenerativeModel("gemini-2.5-flash")
        res = model.generate_content(router_prompt, generation_config={"response_mime_type": "application/json"})
        
        # [FIX QUAN TRá»ŒNG] Dá»n dáº¹p text trÆ°á»›c khi loads
        cleaned_text = clean_json_text(res.text)
        
        return json.loads(cleaned_text)
    except Exception as e: 
        # In lá»—i ra terminal Ä‘á»ƒ debug náº¿u cáº§n
        print(f"âš ï¸ Router Error: {e}")
        # Tráº£ vá» máº·c Ä‘á»‹nh Ä‘á»ƒ app khÃ´ng crash
        return {"intent": "chat_casual", "target_files": [], "rewritten_query": user_prompt}

def load_full_content(file_names, project_id):
    """Load toÃ n vÄƒn ná»™i dung cá»§a nhiá»u file/chÆ°Æ¡ng"""
    if not file_names: return "", []
    
    full_text = ""
    loaded_sources = []
    
    for name in file_names:
        # 1. TÃ¬m trong Chapters (Full)
        res = supabase.table("chapters").select("chapter_number, title, content").eq("story_id", project_id).ilike("title", f"%{name}%").execute()
        
        if res.data:
            item = res.data[0]
            full_text += f"\n\n=== ğŸ“„ SOURCE FILE/CHAP: {item['title']} ===\n{item['content']}\n"
            loaded_sources.append(f"ğŸ“„ {item['title']}")
        else:
            # 2. TÃ¬m trong Bible (Summary Fallback)
            res_bible = supabase.table("story_bible").select("entity_name, description").eq("story_id", project_id).ilike("entity_name", f"%{name}%").execute()
            if res_bible.data:
                item = res_bible.data[0]
                full_text += f"\n\n=== âš ï¸ BIBLE SUMMARY (Chá»‰ lÃ  tÃ³m táº¯t): {item['entity_name']} ===\n{item['description']}\n"
                loaded_sources.append(f"ğŸ—‚ï¸ {item['entity_name']} (Summary)")

    return full_text, loaded_sources

# --- D. [MODULE 2] RULE MINING ---
def get_mandatory_rules(project_id):
    """Láº¥y táº¥t cáº£ cÃ¡c luáº­t (RULE) báº¯t buá»™c"""
    try:
        res = supabase.table("story_bible").select("description").eq("story_id", project_id).ilike("entity_name", "[RULE]%").execute()
        if res.data:
            rules_text = "\n".join([f"- {r['description']}" for r in res.data])
            return f"\nğŸ”¥ --- QUY Táº®C Báº®T BUá»˜C (MANDATORY RULES) ---\n{rules_text}\n"
        return ""
    except: return ""

def extract_rule_raw(user_prompt, ai_response):
    """TrÃ­ch xuáº¥t luáº­t thÃ´ tá»« há»™i thoáº¡i"""
    prompt = f"""
    Dá»±a vÃ o:
    - User: "{user_prompt}"
    - AI: "{ai_response}"
    HÃ£y rÃºt ra 1 QUY Táº®C (RULE) vá» phong cÃ¡ch/format mÃ  User thÃ­ch.
    Output text only (Ngáº¯n gá»n, má»‡nh lá»‡nh thá»©c). VD: "Khi code Python -> Chá»‰ dÃ¹ng JSON."
    """
    try:
        model = genai.GenerativeModel("gemini-2.5-flash")
        res = model.generate_content(prompt)
        return res.text.strip()
    except: return None

def analyze_rule_conflict(new_rule_content, project_id):
    """Check xung Ä‘á»™t luáº­t"""
    # DÃ¹ng hÃ m smart_search_hybrid (tráº£ vá» string) Ä‘á»ƒ AI Ä‘á»c
    similar_rules_str = smart_search_hybrid(new_rule_content, project_id, top_k=3)
    
    if not similar_rules_str:
        return {"status": "NEW", "reason": "KhÃ´ng trÃ¹ng ai cáº£", "suggested_content": new_rule_content}

    judge_prompt = f"""
    Luáº­t Má»›i: "{new_rule_content}"
    Luáº­t CÅ© trong DB: "{similar_rules_str}"
    
    HÃ£y so sÃ¡nh má»‘i quan há»‡:
    - CONFLICT: MÃ¢u thuáº«n trá»±c tiáº¿p.
    - MERGE: CÃ¹ng chá»§ Ä‘á» nhÆ°ng Má»›i chi tiáº¿t hÆ¡n/bá»• sung.
    - NEW: KhÃ¡c chá»§ Ä‘á».
    
    OUTPUT JSON:
    {{
        "status": "CONFLICT" | "MERGE" | "NEW",
        "existing_rule_summary": "TÃ³m táº¯t luáº­t cÅ©",
        "reason": "LÃ½ do",
        "merged_content": "Ná»™i dung gá»™p (náº¿u MERGE). Náº¿u CONFLICT Ä‘á»ƒ null."
    }}
    """
    # --- TRONG HÃ€M analyze_rule_conflict ---
    try:
        model = genai.GenerativeModel("gemini-2.5-flash")
        res = model.generate_content(judge_prompt, generation_config={"response_mime_type": "application/json"})
        
        # === FIX: Gá»ŒI HÃ€M CLEAN TRÆ¯á»šC KHI LOADS ===
        cleaned = clean_json_text(res.text) 
        return json.loads(cleaned)
        # ==========================================
        
    except:
        return {"status": "NEW", "reason": "AI Judge Error", "suggested_content": new_rule_content}

def save_rule_to_db(content, project_id, overwrite=False):
    """LÆ°u luáº­t vÃ o DB"""
    vec = get_embedding(content)
    supabase.table("story_bible").insert({
        "story_id": project_id,
        "entity_name": f"[RULE] {datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "description": content,
        "embedding": vec,
        "source_chapter": 0
    }).execute()

# ==========================================
# ğŸ“± 5. GIAO DIá»†N CHÃNH
# ==========================================
with st.sidebar:
    st.caption(f"ğŸ‘¤ {st.session_state.user.email}")
    projects = supabase.table("stories").select("*").eq("user_id", st.session_state.user.id).execute()
    proj_map = {p['title']: p for p in projects.data}
    
    st.divider()
    selected_proj_name = st.selectbox("ğŸ“‚ Chá»n Dá»± Ãn", ["+ Táº¡o Dá»± Ãn Má»›i"] + list(proj_map.keys()))
    
    if selected_proj_name == "+ Táº¡o Dá»± Ãn Má»›i":
        with st.form("new_proj"):
            title = st.text_input("TÃªn Dá»± Ãn")
            cat = st.selectbox("Loáº¡i", ["Writer", "Coder", "Content Creator"])
            if st.form_submit_button("Táº¡o"):
                supabase.table("stories").insert({"title": title, "category": cat, "user_id": st.session_state.user.id}).execute()
                st.rerun()
        st.stop()
    
    current_proj = proj_map[selected_proj_name]
    proj_id = current_proj['id']
    proj_type = current_proj.get('category', 'Writer')
    
    # Load Persona
    persona = PERSONAS.get(proj_type, PERSONAS['Writer'])
    st.info(f"{persona['icon']} Mode: **{proj_type}**")
    
    if st.button("ğŸšª ÄÄƒng xuáº¥t (Sidebar)"):
        cookie_manager.delete("supabase_access_token")
        for k in list(st.session_state.keys()): del st.session_state[k]
        st.rerun()

st.title(f"{persona['icon']} {selected_proj_name}")

tab1, tab2, tab3 = st.tabs(["âœï¸ Workstation", "ğŸ’¬ Smart Chat With V", "ğŸ“š Project Bible"])

# === TAB 1: WORKSTATION (FULL TITLE & META) ===
with tab1:
    # 1. LOAD DATA
    files = supabase.table("chapters").select("chapter_number, title").eq("story_id", proj_id).order("chapter_number").execute()
    
    f_opts = {}
    for f in files.data:
        display_name = f"File {f['chapter_number']}"
        if f['title']: display_name += f": {f['title']}"
        f_opts[display_name] = f['chapter_number']

    sel_file = st.selectbox("ğŸ“‚ Chá»n File:", ["-- New --"] + list(f_opts.keys()))
    chap_num = f_opts[sel_file] if sel_file != "-- New --" else len(files.data) + 1
    
    db_content, db_review, db_title = "", "", ""
    if sel_file != "-- New --":
        try:
            res = supabase.table("chapters").select("content, review_content, title").eq("story_id", proj_id).eq("chapter_number", chap_num).execute()
            if res.data: 
                db_content = res.data[0].get('content', '')
                db_review = res.data[0].get('review_content', '')
                db_title = res.data[0].get('title', '')
        except: pass

    if 'current_chap_view' not in st.session_state or st.session_state['current_chap_view'] != chap_num:
        st.session_state['review_res'] = db_review
        st.session_state['current_chap_view'] = chap_num

    st.divider()

    # 2. UI EDIT
    col_edit, col_tool = st.columns([2, 1])
    with col_edit:
        chap_title = st.text_input("ğŸ”– TÃªn File", value=db_title, placeholder="VD: Sá»± khá»Ÿi Ä‘áº§u...")
        input_text = st.text_area("Ná»™i dung", value=db_content, height=600)
        
        if st.button("ğŸ’¾ LÆ°u Ná»™i Dung & TÃªn"):
            supabase.table("chapters").upsert({
                "story_id": proj_id, "chapter_number": chap_num, 
                "title": chap_title, "content": input_text
            }, on_conflict="story_id, chapter_number").execute()
            st.toast("ÄÃ£ lÆ°u!", icon="âœ…")
            time.sleep(0.5)
            st.rerun()

    with col_tool:
        st.write("### ğŸ¤– Trá»£ lÃ½ AI")
        # REVIEW
        if st.button("ğŸš€ Review Má»›i", type="primary"):
            if not input_text: st.warning("Trá»‘ng!")
            else:
                with st.status("Äang Ä‘á»c..."):
                    context = smart_search_hybrid(input_text[:500], proj_id)
                    final_prompt = f"TITLE: {chap_title}\nCONTEXT: {context}\nCONTENT: {input_text}\nTASK: {persona['review_prompt']}"
                    res = generate_content_with_fallback(final_prompt, system_instruction=persona['core_instruction'], stream=False)
                    st.session_state['review_res'] = res.text
                    st.rerun()
        
        if 'review_res' in st.session_state and st.session_state['review_res']:
            with st.expander("ğŸ“ Káº¿t quáº£", expanded=True):
                st.markdown(st.session_state['review_res'])
                st.divider()
                if st.button("ğŸ’¾ LÆ°u Review DB"):
                    supabase.table("chapters").update({"review_content": st.session_state['review_res']}).eq("story_id", proj_id).eq("chapter_number", chap_num).execute()
                    st.toast("Saved Review!")

        st.divider()
        # EXTRACT META
        if st.button("ğŸ“¥ TrÃ­ch xuáº¥t Bible"):
            with st.spinner("PhÃ¢n tÃ­ch..."):
                meta_desc = "MÃ´ táº£ ngáº¯n gá»n Má»¤C ÄÃCH, DIá»„N BIáº¾N CHÃNH vÃ  Káº¾T QUáº¢ cá»§a File nÃ y."
                if proj_type == "Coder": meta_desc = "MÃ´ táº£ Má»¤C ÄÃCH, THÃ€NH PHáº¦N CHÃNH (HÃ m/Class) vÃ  INPUT/OUTPUT."
                
                extra_req = f"""
                YÃŠU Cáº¦U Báº®T BUá»˜C: ThÃªm vÃ o Ä‘áº§u JSON má»™t má»¥c tá»•ng há»£p:
                - entity_name: "[META] {chap_title if chap_title else f'File {chap_num}'}"
                - type: "Overview"
                - description: "{meta_desc}"
                """
                ext_prompt = f"TITLE: {chap_title}\nCONTENT: {input_text}\nTASK: {persona['extractor_prompt']}\n{extra_req}"
                try:
                    res = generate_content_with_fallback(ext_prompt, system_instruction="JSON Only", stream=False)
                    st.session_state['extract_json'] = res.text
                except: st.error("Lá»—i AI.")

        if 'extract_json' in st.session_state:
            with st.expander("Preview", expanded=True):
                try:
                    clean = st.session_state['extract_json'].replace("```json", "").replace("```", "").strip()
                    data = json.loads(clean)
                    st.dataframe(pd.DataFrame(data)[['entity_name', 'type', 'description']], hide_index=True)
                    if st.button("ğŸ’¾ Save to Bible"):
                        for item in data:
                            vec = get_embedding(f"{item.get('description')} {item.get('quote', '')}")
                            if vec: 
                                supabase.table("story_bible").insert({
                                    "story_id": proj_id, "entity_name": item['entity_name'],
                                    "description": item['description'], "embedding": vec, "source_chapter": chap_num
                                }).execute()
                        st.success("ÄÃ£ lÆ°u!")
                        del st.session_state['extract_json']
                except Exception as e: st.error(f"Lá»—i Format: {e}")

# === TAB 2: SMART CHAT (FIXED VERSION) ===
with tab2:
    col_left, col_right = st.columns([3, 1])
    
    # --- Cá»˜T PHáº¢I: QUáº¢N LÃ KÃ á»¨C (Giá»¯ nguyÃªn) ---
    with col_right:
        st.write("### ğŸ§  KÃ½ á»©c")
        use_bible = st.toggle("DÃ¹ng Bible Context", value=True)
        
        if 'chat_cutoff' not in st.session_state: st.session_state['chat_cutoff'] = "1970-01-01" 
        if st.button("ğŸ§¹ Clear Screen"):
            st.session_state['chat_cutoff'] = datetime.utcnow().isoformat()
            st.rerun()
        if st.button("ğŸ”„ Hiá»‡n láº¡i toÃ n bá»™"):
             st.session_state['chat_cutoff'] = "1970-01-01"
             st.rerun()
        st.divider()

        with st.expander("ğŸ’ Káº¿t tinh Chat"):
            st.caption("LÆ°u Ã½ chÃ­nh vÃ o Bible.")
            crys_option = st.radio("Pháº¡m vi:", ["20 tin gáº§n nháº¥t", "ToÃ n bá»™ phiÃªn"])
            memory_topic = st.text_input("Chá»§ Ä‘á»:", placeholder="VD: Magic System")
            if st.button("âœ¨ Káº¿t tinh"):
                limit = 20 if crys_option == "20 tin gáº§n nháº¥t" else 100
                chat_data = supabase.table("chat_history").select("*").eq("story_id", proj_id).order("created_at", desc=True).limit(limit).execute().data
                chat_data.reverse()
                if chat_data:
                    with st.spinner("Äang tÃ³m táº¯t..."):
                        summary = crystallize_session(chat_data, persona['role'])
                        if summary != "NO_INFO":
                            st.session_state['crys_summary'] = summary
                            st.session_state['crys_topic'] = memory_topic if memory_topic else f"Chat {datetime.now().strftime('%d/%m')}"
                        else: st.warning("KhÃ´ng cÃ³ thÃ´ng tin giÃ¡ trá»‹.")

    if 'crys_summary' in st.session_state:
        with col_right:
            final_sum = st.text_area("Hiá»‡u chá»‰nh:", value=st.session_state['crys_summary'])
            if st.button("ğŸ’¾ LÆ°u KÃ½ á»©c"):
                vec = get_embedding(final_sum)
                if vec:
                    supabase.table("story_bible").insert({
                        "story_id": proj_id, "entity_name": f"[CHAT] {st.session_state['crys_topic']}",
                        "description": final_sum, "embedding": vec, "source_chapter": 0
                    }).execute()
                    st.toast("ÄÃ£ lÆ°u!")
                    del st.session_state['crys_summary']
                    st.rerun()

    # --- Cá»˜T TRÃI: CHAT UI (LOGIC ÄÃƒ Sá»¬A) ---
    with col_left:
        # 1. LOAD & HIá»‚N THá»Š Lá»ŠCH Sá»¬
        try:
            # [FIX 1]: Láº¥y 50 tin Má»šI NHáº¤T (desc=True) thay vÃ¬ cÅ© nháº¥t
            msgs_data = supabase.table("chat_history").select("*").eq("story_id", proj_id).order("created_at", desc=True).limit(50).execute().data
            
            # Äáº£o ngÆ°á»£c láº¡i Ä‘á»ƒ hiá»ƒn thá»‹ tá»« trÃªn xuá»‘ng dÆ°á»›i (CÅ© -> Má»›i)
            msgs = msgs_data[::-1] if msgs_data else []
            
            # Lá»c theo thá»i gian (Clear screen logic)
            visible_msgs = [m for m in msgs if m['created_at'] > st.session_state['chat_cutoff']]
            
            for i, m in enumerate(visible_msgs):
                with st.chat_message(m['role']):
                    st.markdown(m['content'])
                    
                    # NÃºt Like (Logic cÅ©)
                    if m['role'] == 'model' and i > 0:
                        prev_msg = visible_msgs[i-1]
                        if st.button("â¤ï¸ Dáº¡y V há»c", key=f"like_btn_{i}_{m['id']}", help="AI sáº½ há»c style nÃ y"):
                            raw = extract_rule_raw(prev_msg['content'], m['content'])
                            if raw:
                                ana = analyze_rule_conflict(raw, proj_id)
                                st.session_state['pending_rule'] = {"raw": raw, "analysis": ana}
                                st.rerun()

        except Exception as e: st.error(f"Lá»—i load history: {e}")

        # 2. Xá»¬ LÃ CHAT Má»šI (INPUT)
        if prompt := st.chat_input("Há»i V..."):
            with st.chat_message("user"): st.markdown(prompt)
            
            with st.spinner("V Ä‘ang suy nghÄ©..."):
                # --- A. PREP & ROUTER ---
                current_system_instruction = persona['core_instruction']
                if not use_bible: current_system_instruction += "\n\n[BRAINSTORM MODE] Ignore constraints."

                valid_history_for_context = [m for m in msgs if m['created_at'] > st.session_state['chat_cutoff']]
                recent_pairs = valid_history_for_context[-6:] 
                chat_ctx_text = "\n".join([f"{m['role']}: {m['content']}" for m in recent_pairs])
                
                route = ai_router_pro_v2(prompt, chat_ctx_text)
                intent = route.get('intent')
                target_files = route.get('target_files', [])
                better_query = route.get('rewritten_query', prompt)
                
                ctx = ""
                note = []
                
                # --- B. LOAD CONTEXT ---
                if target_files:
                    raw_content, sources = load_full_content(target_files, proj_id)
                    if raw_content:
                        ctx += f"\nğŸ”¥ --- FULL SOURCE ---\n{raw_content}\n"
                        note.extend(sources)

                if use_bible:
                    mandatory = get_mandatory_rules(proj_id)
                    if mandatory: ctx += mandatory
                    
                    if intent == "search_bible" or (not target_files):
                        bible_res = smart_search_hybrid(better_query, proj_id)
                        if bible_res: 
                            ctx += f"\n--- VECTOR MEMORY ---\n{bible_res}\n"
                            note.append("Vector")

                recent = "\n".join([f"{m['role']}: {m['content']}" for m in valid_history_for_context[-10:]])
                ctx += f"\n--- RECENT ---\n{recent}"
                
                final_prompt = f"CONTEXT:\n{ctx}\n\nUSER QUERY: {prompt}\n(Intent: {better_query})"

                # --- C. GENERATE ---
                try:
                    res_stream = generate_content_with_fallback(final_prompt, system_instruction=current_system_instruction)
                    
                    with st.chat_message("assistant"):
                        if note: st.caption(f"ğŸ“š {', '.join(note)}")
                        # Stream ná»™i dung ra mÃ n hÃ¬nh
                        full_res = st.write_stream(res_stream) 
                        
                        # [QUAN TRá»ŒNG] Náº¿u stream bá»‹ lá»—i generator, convert sang text thÆ°á»ng
                        if not isinstance(full_res, str): 
                             full_res = str(full_res)

                    # LÆ°u DB
                    supabase.table("chat_history").insert([
                        {"story_id": proj_id, "role": "user", "content": str(prompt)},
                        {"story_id": proj_id, "role": "model", "content": str(full_res)}
                    ]).execute()
                    
                    # [FIX 2]: Bá» Lá»†NH st.rerun() á» ÄÃ‚Y!
                    # Äá»ƒ tin nháº¯n vá»«a chat khÃ´ng bá»‹ load láº¡i (trÃ¡nh chá»›p mÃ n hÃ¬nh)
                    # Láº§n chat tiáº¿p theo nÃ³ sáº½ tá»± hiá»‡n trong lá»‹ch sá»­.

                except Exception as e: st.error(f"Lá»—i: {e}")

    # --- E. UI QUYáº¾T Äá»ŠNH LUáº¬T (Náº±m ngoÃ i cÃ¹ng) ---
    if 'pending_rule' in st.session_state:
        pending = st.session_state['pending_rule']
        ana = pending['analysis']
        status = ana.get('status')
        
        with st.status("ğŸ§  Äang cáº­p nháº­t tri thá»©c...", expanded=True):
            st.write(f"**Luáº­t má»›i:** {pending['raw']}")
            
            col1, col2 = st.columns(2)
            
            if status == "NEW":
                st.success("Luáº­t má»›i há»£p lá»‡.")
                if col1.button("LÆ°u ngay"):
                    save_rule_to_db(pending['raw'], proj_id)
                    st.toast("ÄÃ£ há»c!")
                    del st.session_state['pending_rule']
                    st.rerun()
            elif status == "CONFLICT":
                st.error(f"Xung Ä‘á»™t: {ana.get('existing_rule_summary')}")
                if col1.button("Ghi Ä‘Ã¨"):
                    save_rule_to_db(pending['raw'], proj_id, overwrite=True)
                    del st.session_state['pending_rule']
                    st.rerun()
            elif status == "MERGE":
                st.warning(f"TÆ°Æ¡ng tá»±: {ana.get('existing_rule_summary')}")
                if col1.button("Gá»™p"):
                    save_rule_to_db(ana.get('merged_content'), proj_id, overwrite=True)
                    del st.session_state['pending_rule']
                    st.rerun()
            
            if col2.button("Há»§y"):
                del st.session_state['pending_rule']
                st.rerun()
# === TAB 3: BIBLE (Cáº¬P NHáº¬T: THÃŠM/Sá»¬A/SEARCH/MERGE) ===
with tab3:
    st.subheader("ğŸ“š Project Bible Manager")
    
    # 1. THANH TÃŒM KIáº¾M
    col_search, col_ref = st.columns([4, 1])
    with col_search:
        search_kw = st.text_input("ğŸ” TÃ¬m kiáº¿m trong Bible", placeholder="Nháº­p tá»« khÃ³a Ä‘á»ƒ lá»c danh sÃ¡ch bÃªn dÆ°á»›i...")
    with col_ref:
        if st.button("ğŸ”„ Refresh", use_container_width=True): st.rerun()

    # 2. LOAD DATA & FILTER
    bible_query = supabase.table("story_bible").select("*").eq("story_id", proj_id).order("created_at", desc=True).execute()
    bible_data = bible_query.data if bible_query.data else []

    # Filter logic
    filtered_bible = []
    if search_kw:
        kw = search_kw.lower()
        filtered_bible = [b for b in bible_data if kw in b['entity_name'].lower() or kw in b['description'].lower()]
    else:
        filtered_bible = bible_data

    # Map ID -> Item
    opts = {f"{b['entity_name']}": b for b in filtered_bible}

    # 3. KHU Vá»°C THÃŠM Má»šI
    with st.expander("â• ThÃªm Bible thá»§ cÃ´ng", expanded=False):
        with st.form("add_bible_form"):
            new_name = st.text_input("TÃªn má»¥c (Entity Name)")
            new_desc = st.text_area("MÃ´ táº£ chi tiáº¿t")
            if st.form_submit_button("LÆ°u má»›i"):
                if not new_name or not new_desc:
                    st.error("Vui lÃ²ng nháº­p Ä‘á»§ thÃ´ng tin!")
                else:
                    with st.spinner("Äang vector hÃ³a..."):
                        vec = get_embedding(f"{new_name}: {new_desc}")
                        if vec:
                            supabase.table("story_bible").insert({
                                "story_id": proj_id,
                                "entity_name": new_name,
                                "description": new_desc,
                                "embedding": vec,
                                "source_chapter": 0 # 0 = Manual
                            }).execute()
                            st.success("ÄÃ£ thÃªm thÃ nh cÃ´ng!")
                            time.sleep(1)
                            st.rerun()
                        else:
                            st.error("Lá»—i táº¡o Embedding.")

    st.divider()

    # 4. DANH SÃCH & THAO TÃC
    if filtered_bible:
        selections = st.multiselect(
            f"Chá»n má»¥c Ä‘á»ƒ thao tÃ¡c (Äang hiá»ƒn thá»‹ {len(filtered_bible)} má»¥c):", 
            list(opts.keys()),
            key="bible_selector"
        )
        
        col_actions = st.columns([1, 1, 2])
        
        # NÃšT XÃ“A
        with col_actions[0]:
            if st.button("ğŸ”¥ XÃ³a Má»¥c Chá»n", use_container_width=True, disabled=len(selections)==0):
                ids = [opts[k]['id'] for k in selections]
                supabase.table("story_bible").delete().in_("id", ids).execute()
                st.success("ÄÃ£ xÃ³a!")
                time.sleep(0.5)
                st.rerun()

        # NÃšT Gá»˜P (MERGE)
        with col_actions[1]:
            if st.button("ğŸ§¬ Gá»™p (AI Merge)", use_container_width=True, disabled=len(selections)<2):
                items = [opts[k] for k in selections]
                txt = "\n".join([f"- {i['description']}" for i in items])
                prompt_merge = f"Gá»™p cÃ¡c má»¥c sau thÃ nh 1 ná»™i dung duy nháº¥t:\n{txt}"
                
                try:
                    with st.spinner("AI Ä‘ang gá»™p..."):
                        res = generate_content_with_fallback(prompt_merge, system_instruction="Merge Expert", stream=False)
                        merged_text = res.text
                        
                        if merged_text and merged_text.strip():
                            vec = get_embedding(merged_text)
                            if vec:
                                # Insert cÃ¡i má»›i
                                supabase.table("story_bible").insert({
                                    "story_id": proj_id, "entity_name": items[0]['entity_name'],
                                    "description": merged_text, "embedding": vec, "source_chapter": items[0]['source_chapter']
                                }).execute()
                                # XÃ³a cÃ¡i cÅ©
                                ids = [i['id'] for i in items]
                                supabase.table("story_bible").delete().in_("id", ids).execute()
                                st.success("Gá»™p xong!")
                                time.sleep(0.5)
                                st.rerun()
                            else: st.error("Lá»—i Embedding.")
                        else: st.error("AI tráº£ vá» rá»—ng.")
                except Exception as e: st.error(f"Lá»—i: {e}")

        # KHU Vá»°C Sá»¬A (EDIT)
        if len(selections) == 1:
            st.info("ğŸ› ï¸ Cháº¿ Ä‘á»™ chá»‰nh sá»­a")
            item_to_edit = opts[selections[0]]
            with st.form("edit_bible_form"):
                edit_name = st.text_input("Sá»­a TÃªn", value=item_to_edit['entity_name'])
                edit_desc = st.text_area("Sá»­a MÃ´ táº£", value=item_to_edit['description'], height=150)
                
                if st.form_submit_button("Cáº­p nháº­t & Re-Vectorize"):
                    with st.spinner("Äang cáº­p nháº­t..."):
                        vec = get_embedding(f"{edit_name}: {edit_desc}")
                        if vec:
                            supabase.table("story_bible").update({
                                "entity_name": edit_name,
                                "description": edit_desc,
                                "embedding": vec
                            }).eq("id", item_to_edit['id']).execute()
                            st.success("ÄÃ£ cáº­p nháº­t!")
                            time.sleep(1)
                            st.rerun()
                        else:
                            st.error("Lá»—i vector hÃ³a.")

        st.divider()
        st.dataframe(
            pd.DataFrame(filtered_bible)[['entity_name', 'description', 'created_at']], 
            use_container_width=True,
            hide_index=True
        )
    else:
        st.info("KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u phÃ¹ há»£p.")
    
    st.divider()
    with st.expander("ğŸ’€ Danger Zone (XÃ³a táº¥t cáº£)"):
        st.warning("âš ï¸ Cáº¢NH BÃO: HÃ nh Ä‘á»™ng nÃ y sáº½ xÃ³a sáº¡ch toÃ n bá»™ Bible cá»§a dá»± Ã¡n nÃ y. Báº¡n sáº½ cáº§n trÃ­ch xuáº¥t láº¡i tá»« Ä‘áº§u.")
        col_dang1, col_dang2 = st.columns([3, 1])
        with col_dang2:
            if st.button("ğŸ’£ XÃ³a sáº¡ch Bible & Reset", type="primary", use_container_width=True):
                try:
                    supabase.table("story_bible").delete().eq("story_id", proj_id).execute()
                    st.success("ÄÃ£ dá»n sáº¡ch sáº½!")
                    time.sleep(1)
                    st.rerun()
                except Exception as e:
                    st.error(f"Lá»—i khi xÃ³a: {e}")







