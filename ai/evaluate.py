# ai/evaluate.py - V7 dynamic re-planning: evaluate_step_outcome, replan_after_step, is_answer_sufficient
import json
from typing import Dict, List, Optional, Tuple

from ai.service import AIService, _get_default_tool_model


def is_answer_sufficient(
    user_prompt: str,
    model_answer: str,
    context_preview: str = "",
    context_needs: Optional[List[str]] = None,
) -> bool:
    """Th·∫©m ƒë·ªãnh c√¢u tr·∫£ l·ªùi: heuristic tr∆∞·ªõc, LLM khi c·∫ßn. Tr·∫£ v·ªÅ True n·∫øu ƒë·ªß √Ω, False n·∫øu c·∫ßn fallback (ƒë·ªçc th√™m ch∆∞∆°ng)."""
    if not (user_prompt and model_answer):
        return True

    context_needs = context_needs or []
    ctx_lower = (context_preview or "").lower()
    prompt_lower = (user_prompt or "").lower()

    # Heuristic 1: User c·∫ßn n·ªôi dung ch∆∞∆°ng nh∆∞ng context kh√¥ng c√≥ chapter content -> ch∆∞a ƒë·ªß
    if "chapter" in context_needs:
        has_chapter_content = (
            "target content" in ctx_lower
            or "n·ªôi dung ch∆∞∆°ng" in ctx_lower
            or "related files" in ctx_lower
            or "reverse lookup" in ctx_lower
        )
        if not has_chapter_content:
            return False

    # Heuristic 2: C√¢u h·ªèi c·ª• th·ªÉ (ch∆∞∆°ng/t√≥m t·∫Øt/l√†m g√¨) m√† tr·∫£ l·ªùi qu√° ng·∫Øn
    if len(model_answer.strip()) < 80 and any(
        k in prompt_lower for k in ("ch∆∞∆°ng", "t√≥m t·∫Øt", "l√†m g√¨", "n·ªôi dung", "di·ªÖn ra")
    ):
        return False

    # Heuristic 3: Tr·∫£ l·ªùi mang t√≠nh t·ª´ ch·ªëi ho·∫∑c kh√¥ng c√≥ th√¥ng tin
    if any(
        phrase in (model_answer or "").lower()
        for phrase in ("ch∆∞a c√≥ th√¥ng tin", "kh√¥ng t√¨m th·∫•y", "ch∆∞a c√≥ d·ªØ li·ªáu", "ch∆∞a c√≥ n·ªôi dung")
    ) and any(k in prompt_lower for k in ("ch∆∞∆°ng", "t√≥m t·∫Øt", "n·ªôi dung")):
        return False

    # Kh√¥ng k·∫øt lu·∫≠n ƒë∆∞·ª£c b·∫±ng heuristic -> g·ªçi LLM
    prompt = f"""User h·ªèi: "{user_prompt[:400]}"

C√¢u tr·∫£ l·ªùi hi·ªán t·∫°i:
{model_answer[:1500]}

Context ƒë√£ d√πng (r√∫t g·ªçn): {context_preview[:500] if context_preview else "(kh√¥ng)"}

Nhi·ªám v·ª•: C√¢u tr·∫£ l·ªùi tr√™n c√≥ ƒê·ª¶ √Ω, tr·ª±c ti·∫øp ƒë√°p ·ª©ng c√¢u h·ªèi c·ªßa user kh√¥ng? N·∫øu c√≤n chung chung, thi·∫øu chi ti·∫øt t·ª´ n·ªôi dung ch∆∞∆°ng/vƒÉn b·∫£n m√† user ƒëang h·ªèi th√¨ tr·∫£ false.
Tr·∫£ v·ªÅ ƒê√öNG M·ªòT JSON: {{ "sufficient": true ho·∫∑c false }}"""
    try:
        r = AIService.call_openrouter(
            messages=[{"role": "user", "content": prompt}],
            model=_get_default_tool_model(),
            temperature=0,
            max_tokens=50,
            response_format={"type": "json_object"},
        )
        content = AIService.clean_json_text(r.choices[0].message.content or "{}")
        data = json.loads(content)
        return bool(data.get("sufficient", True))
    except Exception:
        return True


def evaluate_step_outcome(intent: str, ctx_text: str, sources: List[str]) -> Tuple[bool, str]:
    """
    ƒê√°nh gi√° b∆∞·ªõc v·ª´a ch·∫°y: c√≥ "th·∫•t b·∫°i" (kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu) c·∫ßn c√¢n nh·∫Øc re-plan kh√¥ng.
    Returns: (should_consider_replan, reason).
    """
    if not intent or intent in ("chat_casual", "ask_user_clarification", "update_data", "web_search"):
        return False, ""
    ctx_upper = (ctx_text or "").upper()
    src_list = sources or []

    if intent == "search_context":
        has_any = (
            "üìö" in str(src_list) or "KNOWLEDGE BASE" in ctx_upper
            or "TARGET CONTENT" in ctx_text or "N·ªòI DUNG CH∆Ø∆†NG" in ctx_text
            or "Timeline" in ctx_upper or "Chunk" in str(src_list) or "chunk" in str(src_list).lower()
        )
        if not has_any or (len(ctx_text or "") < 200):
            return True, "search_context: kh√¥ng c√≥ d·ªØ li·ªáu Bible, chapter, timeline hay chunk"
        return False, ""

    if intent == "query_Sql":
        if "KNOWLEDGE BASE (query_Sql" not in ctx_text and "üîç Query SQL" not in str(src_list):
            return True, "query_Sql: kh√¥ng c√≥ d·ªØ li·ªáu Bible/ƒë·ªëi t∆∞·ª£ng"
        return False, ""

    return False, ""


def replan_after_step(
    user_prompt: str,
    cumulative_context: str,
    step_results: List[Dict],
    step_just_done: Dict,
    outcome_reason: str,
    remaining_plan: List[Dict],
    project_id: Optional[str] = None,
) -> Tuple[str, str, List[Dict]]:
    """
    G·ªçi LLM quy·∫øt ƒë·ªãnh: continue / replace / abort sau khi m·ªôt b∆∞·ªõc th·∫•t b·∫°i (kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu).
    Returns: (action, reason, new_plan). new_plan ch·ªâ c√≥ khi action == "replace".
    """
    intent_done = step_just_done.get("intent", "chat_casual")
    args_done = step_just_done.get("args") or {}
    remaining_summary = json.dumps([{"step_id": s.get("step_id"), "intent": s.get("intent")} for s in remaining_plan], ensure_ascii=False)

    prompt_text = f"""User h·ªèi: "{user_prompt[:500]}"

V·ª´a th·ª±c thi xong b∆∞·ªõc: intent={intent_done}, args={json.dumps(args_done, ensure_ascii=False)[:300]}.
K·∫øt qu·∫£ b∆∞·ªõc n√†y: {outcome_reason} (kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu / th·∫•t b·∫°i).

Context ƒë√£ t√≠ch l≈©y (r√∫t g·ªçn): {cumulative_context[:2500]}...

K·∫ø ho·∫°ch c√≤n l·∫°i (ch∆∞a ch·∫°y): {remaining_summary}

Nhi·ªám v·ª•: Quy·∫øt ƒë·ªãnh m·ªôt trong ba:
1. **continue** ‚Äì Gi·ªØ nguy√™n plan c√≤n l·∫°i, ch·∫°y ti·∫øp (th·ª≠ b∆∞·ªõc ti·∫øp theo).
2. **replace** ‚Äì Thay th·∫ø plan c√≤n l·∫°i b·∫±ng plan m·ªõi (vd: thay "t√¨m file A" b·∫±ng "t√¨m file B", ho·∫∑c ƒë·ªïi intent kh√°c ph√π h·ª£p). Tr·∫£ v·ªÅ new_plan l√† m·∫£ng b∆∞·ªõc thay th·∫ø (format gi·ªëng plan: step_id, intent, args v·ªõi query_refined, target_files, target_bible_entities, chapter_range, ...).
3. **abort** ‚Äì D·ª´ng th·ª±c thi, kh√¥ng ch·∫°y th√™m b∆∞·ªõc; tr·∫£ l·ªùi d·ª±a tr√™n context hi·ªán c√≥.

Tr·∫£ v·ªÅ ƒê√öNG M·ªòT JSON (ch·ªâ JSON, kh√¥ng gi·∫£i th√≠ch):
{{ "action": "continue" | "replace" | "abort", "reason": "L√Ω do ng·∫Øn", "new_plan": [] }}

V·ªõi action=replace th√¨ new_plan ph·∫£i c√≥ √≠t nh·∫•t 1 b∆∞·ªõc. V·ªõi continue/abort th√¨ new_plan ƒë·ªÉ []."""

    try:
        r = AIService.call_openrouter(
            messages=[
                {"role": "system", "content": "B·∫°n l√† V7 Re-planner. Ch·ªâ tr·∫£ v·ªÅ JSON v·ªõi action, reason, new_plan."},
                {"role": "user", "content": prompt_text},
            ],
            model=_get_default_tool_model(),
            temperature=0.2,
            max_tokens=600,
            response_format={"type": "json_object"},
        )
        content = AIService.clean_json_text(r.choices[0].message.content or "{}")
        data = json.loads(content)
        action = (data.get("action") or "continue").strip().lower()
        if action not in ("continue", "replace", "abort"):
            action = "continue"
        reason = str(data.get("reason") or "").strip() or outcome_reason
        new_plan = data.get("new_plan") if isinstance(data.get("new_plan"), list) else []
        if action == "replace" and not new_plan:
            action = "continue"
            new_plan = []
        return action, reason, new_plan
    except Exception as e:
        print(f"replan_after_step error: {e}")
        return "continue", "", []
